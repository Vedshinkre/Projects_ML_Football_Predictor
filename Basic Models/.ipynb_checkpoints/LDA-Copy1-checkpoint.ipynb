{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc70686b-e030-4a77-8c0e-cfcba865da64",
   "metadata": {},
   "source": [
    "### **K-Nearest Neighbors (KNN) Classification**  \n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple, non-parametric classification algorithm that assigns a class to a data point based on the majority class of its nearest neighbors. It is widely used for classification and regression tasks due to its ease of implementation and intuitive approach.  \n",
    "\n",
    "### **How It Works:**  \n",
    "- **Instance-Based Learning**: KNN does not explicitly learn a model but stores the entire dataset and classifies new points based on proximity to existing data.  \n",
    "- **Distance Metric**: Computes the distance between points using metrics like **Euclidean distance**, **Manhattan distance**, or **Minkowski distance**.  \n",
    "- **Voting Mechanism**: Assigns a class based on the majority vote of the **k** nearest neighbors. A smaller **k** is more sensitive to noise, while a larger **k** smooths decision boundaries.  \n",
    "- **Weighted Voting (Optional)**: Some versions weight neighbors by distance, giving closer points more influence in classification.  \n",
    "\n",
    "### **Advantages:**  \n",
    "✅ **Simple & Intuitive**: Easy to understand and implement without making strong assumptions about data distribution.  \n",
    "✅ **Non-Parametric**: Works well with complex decision boundaries since it does not assume a specific functional form.  \n",
    "✅ **Handles Multi-Class Problems**: Naturally supports multiple classes without modification.  \n",
    "✅ **Adaptable to Different Distance Metrics**: Can be customized using different distance functions to suit various data types.  \n",
    "\n",
    "### **Disadvantages:**  \n",
    "❌ **Computationally Expensive**: Requires storing the entire dataset and computing distances at prediction time, making it slow for large datasets.  \n",
    "❌ **Sensitive to Irrelevant Features**: Performance degrades if irrelevant or redundant features dominate meaningful ones.  \n",
    "❌ **Imbalanced Classes Issue**: May favor majority classes unless weighting techniques are applied.  \n",
    "❌ **Curse of Dimensionality**: High-dimensional data can make distance calculations less meaningful, reducing effectiveness.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec6edd6-bf3f-479d-a852-c851ab489b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading all the necesaary dependecies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea8b79c-f9d0-4995-bb81-fec4bf879100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Data_Formatting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3406a2-ddbd-4e76-b11c-776d96638044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Ultimate_Hyperparameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe29c75b-a26d-4a71-83ab-cae848ae1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Parameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95630408-0eb2-4105-9444-38f4ee60f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60cbd32d-f0f7-4607-aeb0-3372fa373692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training dataset \n",
    "train_path = Path(\"../Data/premierleague_team_data.csv\")\n",
    "matches = pd.read_csv(train_path)\n",
    "\n",
    "#loading the testing data \n",
    "test_path = Path(\"../Data/premierleague_test_team_data.csv\")\n",
    "test_matches = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2baa6e56-1eac-41e6-8a92-9207df490d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training dataset with rank\n",
    "train_path = Path(\"../Data/premierleague_rank_team_data.csv\")\n",
    "new_matches = pd.read_csv(train_path)\n",
    "\n",
    "#loading the testing data with rank\n",
    "test_path = Path(\"../Data/premierleague_rank_test_team_data.csv\")\n",
    "new_test_matches = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67c7dfc4-2e79-40e0-8d6e-33edeaae1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(matches, test_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3e08058-5f55-4b99-8963-8450c24370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(new_matches, new_test_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435f728-6654-4fd0-8e72-d8deb7dcdfb2",
   "metadata": {},
   "source": [
    "### LDA using Baseline Predictors (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73e79954-582f-45fd-9f0a-f52f8b9db86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_lda_base(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "    \n",
    "    static_predictors =  parameters_base(Train,Test)\n",
    "\n",
    "    # Train an LDA model\n",
    "    lda_clf = LinearDiscriminantAnalysis(solver=\"lsqr\",shrinkage=best_shrinkage)\n",
    "    lda_clf.fit(Train[static_predictors], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = lda_clf.predict(test_year[static_predictors])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"Linear Discriminant Analysis\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525616cf-bfef-44e3-9c3e-26feb0d37250",
   "metadata": {},
   "source": [
    "### LDA using Baseline Predictors + Rolling Predictors (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93c53610-73a9-4e69-b753-4a895ca70548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_lda_roll(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "     \n",
    "    all_predictors = parameters_roll(Train,Test)\n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "    # Train an LDA model\n",
    "    lda_clf = LinearDiscriminantAnalysis(solver=\"lsqr\" ,shrinkage=best_shrinkage ) \n",
    "    lda_clf.fit(Train[ all_predictors ], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = lda_clf.predict(test_year[ all_predictors ])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"Linear Discriminant Analysis\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281f88e-8815-4ae5-9bc5-9c1c13aa33e1",
   "metadata": {},
   "source": [
    "### LDA using  Full Feature Set (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e2ac509-6e12-4c23-a9d1-ede300b8dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_lda_full(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "\n",
    "    all_predictors = parameters_full(Train,Test)\n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "    # Train an LDA model\n",
    "    lda_clf = LinearDiscriminantAnalysis(solver=\"lsqr\",shrinkage=best_shrinkage)\n",
    "    lda_clf.fit(Train[ all_predictors ], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = lda_clf.predict(test_year[ all_predictors ])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"Linear Discriminant Analysis\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
