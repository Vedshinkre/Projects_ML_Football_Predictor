{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc70686b-e030-4a77-8c0e-cfcba865da64",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)\n",
    "\n",
    "Linear Discriminant Analysis (LDA) is a dimensionality reduction and classification technique used in machine learning. It aims to find the linear combination of features that best separate two or more classes. Unlike logistic regression, which focuses on estimating probabilities, LDA maximizes class separability by projecting data onto a lower-dimensional space.\n",
    "\n",
    "### How It Works:\n",
    "- **Assumption of Normality**: Assumes that the features follow a Gaussian distribution for each class.\n",
    "- **Class Separation**: Finds a linear decision boundary by maximizing the ratio of between-class variance to within-class variance.\n",
    "- **Bayes’ Theorem**: Uses Bayes' theorem to estimate the probability of a data point belonging to a class and assigns it to the class with the highest probability.\n",
    "- **Dimensionality Reduction**: Reduces the number of features while retaining the most discriminative information.\n",
    "\n",
    "### Advantages:\n",
    "✅ **Handles Multi-Class Problems**: Unlike logistic regression, LDA naturally extends to multiple classes.  \n",
    "✅ **Effective for Linearly Separable Data**: Works well when the class distributions have distinct means.  \n",
    "✅ **Reduces Overfitting**: By projecting data onto lower dimensions, it can help prevent overfitting in high-dimensional datasets.  \n",
    "✅ **Computationally Efficient**: Faster to train and evaluate compared to more complex models like Support Vector Machines (SVMs).  \n",
    "\n",
    "### Disadvantages:\n",
    "❌ **Assumption of Normality**: Performance may degrade if the feature distribution is highly non-Gaussian.  \n",
    "❌ **Sensitive to Outliers**: Outliers can affect the mean and covariance estimates, leading to poor classification.  \n",
    "❌ **Limited to Linear Boundaries**: Similar to logistic regression, it struggles with non-linear relationships unless extended with kernel methods.  \n",
    "❌ **Requires Balanced Classes**: Works best when class distributions are approximately equal; otherwise, it may be biased toward the majority class.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ec6edd6-bf3f-479d-a852-c851ab489b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading all the necesaary dependecies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ea8b79c-f9d0-4995-bb81-fec4bf879100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Data_Formatting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c3406a2-ddbd-4e76-b11c-776d96638044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Ultimate_Hyperparameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20744efb-51c3-4334-9b70-c6198530c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Parameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95630408-0eb2-4105-9444-38f4ee60f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60cbd32d-f0f7-4607-aeb0-3372fa373692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training dataset \n",
    "train_path = Path(\"../Data/premierleague_team_data.csv\")\n",
    "matches = pd.read_csv(train_path)\n",
    "\n",
    "#loading the testing data \n",
    "test_path = Path(\"../Data/premierleague_test_team_data.csv\")\n",
    "test_matches = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2baa6e56-1eac-41e6-8a92-9207df490d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training dataset with rank\n",
    "train_path = Path(\"../Data/premierleague_rank_team_data.csv\")\n",
    "new_matches = pd.read_csv(train_path)\n",
    "\n",
    "#loading the testing data with rank\n",
    "test_path = Path(\"../Data/premierleague_rank_test_team_data.csv\")\n",
    "new_test_matches = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c7dfc4-2e79-40e0-8d6e-33edeaae1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(matches, test_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3e08058-5f55-4b99-8963-8450c24370d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(new_matches, new_test_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435f728-6654-4fd0-8e72-d8deb7dcdfb2",
   "metadata": {},
   "source": [
    "### LDA using Baseline Predictors (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73e79954-582f-45fd-9f0a-f52f8b9db86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_lda_base(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "    \n",
    "    static_predictors =  parameters_base(Train,Test)\n",
    "\n",
    "    # Train an LDA model\n",
    "    lda_clf = LinearDiscriminantAnalysis(solver=\"lsqr\",shrinkage=best_shrinkage)\n",
    "    lda_clf.fit(Train[static_predictors], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = lda_clf.predict(test_year[static_predictors])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"Linear Discriminant Analysis\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525616cf-bfef-44e3-9c3e-26feb0d37250",
   "metadata": {},
   "source": [
    "### LDA using Baseline Predictors + Rolling Predictors (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93c53610-73a9-4e69-b753-4a895ca70548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_lda_roll(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "     \n",
    "    all_predictors = parameters_roll(Train,Test)\n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "    # Train an LDA model\n",
    "    lda_clf = LinearDiscriminantAnalysis(solver=\"lsqr\" ,shrinkage=best_shrinkage ) \n",
    "    lda_clf.fit(Train[ all_predictors ], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = lda_clf.predict(test_year[ all_predictors ])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"Linear Discriminant Analysis\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281f88e-8815-4ae5-9bc5-9c1c13aa33e1",
   "metadata": {},
   "source": [
    "### LDA using  Full Feature Set (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e2ac509-6e12-4c23-a9d1-ede300b8dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_lda_full(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "\n",
    "    all_predictors = parameters_full(Train,Test)\n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "    # Train an LDA model\n",
    "    lda_clf = LinearDiscriminantAnalysis(solver=\"lsqr\",shrinkage=best_shrinkage)\n",
    "    lda_clf.fit(Train[ all_predictors ], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = lda_clf.predict(test_year[ all_predictors ])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"Linear Discriminant Analysis\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
