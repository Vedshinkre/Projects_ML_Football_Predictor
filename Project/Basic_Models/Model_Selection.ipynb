{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700635c0-6908-45c0-bdb0-b61813abaa74",
   "metadata": {},
   "source": [
    "# Basic Classification Models: LDA, QDA, KNN, and Logistic Regression  \n",
    "\n",
    " In this section, we explore four fundamental classification models: **Linear Discriminant Analysis (LDA)**, **Quadratic Discriminant Analysis (QDA)**, **K-Nearest Neighbors (KNN)**, and **Logistic Regression**. These models serve as the foundation for many machine learning classification problems.\n",
    " \n",
    "## 1. Linear Discriminant Analysis (LDA)  \n",
    "LDA finds a linear combination of features that best separates classes, assuming normally distributed data with the same covariance.  \n",
    "\n",
    "âœ… Works well for linearly separable data  \n",
    "âŒ Struggles with non-linear class boundaries  \n",
    "\n",
    "## 2. Quadratic Discriminant Analysis (QDA)  \n",
    "QDA extends LDA by allowing each class to have its own covariance matrix, leading to quadratic decision boundaries.  \n",
    "\n",
    "âœ… More flexible than LDA  \n",
    "âŒ Requires more data, prone to overfitting  \n",
    "\n",
    "## 3. K-Nearest Neighbors (KNN)  \n",
    "KNN classifies a point based on the majority class of its **k** closest neighbors using a distance metric.  \n",
    "\n",
    "âœ… No assumptions about data distribution  \n",
    "âŒ Computationally expensive, sensitive to noise  \n",
    "\n",
    "## 4. Logistic Regression  \n",
    "Logistic Regression predicts class probabilities using a sigmoid function and is best for binary classification.  \n",
    "\n",
    "âœ… Simple, interpretable, works well for linear problems  \n",
    "âŒ Struggles with non-linearity unless features are transformed  \n",
    "\n",
    "## Summary  \n",
    "- **LDA/QDA**: Good for normally distributed data, LDA for linear, QDA for non-linear.  \n",
    "- **KNN**: Flexible but slow on large datasets.  \n",
    "- **Logistic Regression**: Best for simple binary classification with linear relationships.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37915954-7569-417e-9127-ce9bdca85716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading all the necesaary dependecies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0655eca3-7e2a-4f55-919b-8bbe7fde4fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea9c0d0-e919-411f-88fb-254cb8c51d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Data_Formatting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "970b8815-d6e5-4de9-9196-ed978106523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Ultimate_Hyperparameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d263c3-b639-4b88-9346-990a3a41b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Data/Parameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0348ebb9-13cd-4ae7-8de1-13559cd85e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training dataset \n",
    "train_path = Path(\"../Data/premierleague_team_data.csv\")\n",
    "matches = pd.read_csv(train_path)\n",
    "\n",
    "#loading the testing data \n",
    "test_path = Path(\"../Data/premierleague_test_team_data.csv\")\n",
    "test_matches = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19d4210-4aca-4714-908d-4595702758fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training dataset with rank\n",
    "train_path = Path(\"../Data/premierleague_rank_team_data.csv\")\n",
    "new_matches = pd.read_csv(train_path)\n",
    "\n",
    "#loading the testing data with rank\n",
    "test_path = Path(\"../Data/premierleague_rank_test_team_data.csv\")\n",
    "new_test_matches = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b967b7-49c7-4b64-82df-3bc53cbacda4",
   "metadata": {},
   "source": [
    "# Best Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812d0bd-dbd7-4820-a9b7-7eab8ef11c99",
   "metadata": {},
   "source": [
    "## Choosing the Best Overall Model\n",
    "\n",
    "In our analysis, we have evaluated four different machine learning models: **Bagging, Gradient Boosting, Decision Tree, and Random Forest**. Each of these models has been tested on multiple years of data, and their performance has been measured using **accuracy** and **precision**.\n",
    "\n",
    "### Why Do We Need to Choose the Best Model?\n",
    "\n",
    "1. **Consistency Across Years**  \n",
    "   Some models may perform well in certain years but not in others. Selecting the best overall model ensures that we choose the one that provides **consistent performance across multiple years** rather than excelling only in specific cases.\n",
    "\n",
    "2. **Generalization to Future Data**  \n",
    "   The goal is to make predictions on new, unseen data. A model that performs well across different years is more **robust and reliable** for future predictions.\n",
    "\n",
    "3. **Maximizing Accuracy and Precision**  \n",
    "   By comparing the performance of all models, we can **identify the model with the highest accuracy and precision**. This helps in minimizing errors and improving decision-making.\n",
    "\n",
    "4. **Avoiding Overfitting**  \n",
    "   Some models might perform exceptionally well on training data but fail on test data. By analyzing results across multiple years, we ensure that the chosen model is **not overfitting** and generalizes well.\n",
    "\n",
    "### How Will We Choose the Best Model?\n",
    "We will compare all models based on:\n",
    "- **Accuracy** (how often the model makes correct predictions)  \n",
    "- **Precision** (how reliable the model's positive predictions are)  \n",
    "\n",
    "The model that consistently achieves the highest accuracy and precision across multiple years will be selected as the **best overall model**.\n",
    "\n",
    "By following this approach, we ensure that our chosen model is the most reliable and effective for making predictions. ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194982f-4143-437e-bc68-d727346c52dc",
   "metadata": {},
   "source": [
    "## Models with Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c732be7e-ca2c-4395-8c01-6a8b5971411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all models\n",
    "def best_basic_model_baseline(A, B):\n",
    "    KNN_results = make_yearly_predictions_knn_base(A, B)\n",
    "    LDA_results =make_yearly_predictions_lda_base(A, B)\n",
    "    LR_results = make_yearly_predictions_lr_base(A, B)\n",
    "    QDA_results = make_yearly_predictions_qda_base(A, B)\n",
    "\n",
    "    # Combine all results\n",
    "    all_results = pd.concat([KNN_results, LDA_results, LR_results, QDA_results], ignore_index=True)\n",
    "\n",
    "    # Find best accuracy & precision for each year\n",
    "    best_per_year = all_results.loc[all_results.groupby(\"Year\")[\"Accuracy\"].idxmax()]\n",
    "    best_per_year_precision = all_results.loc[all_results.groupby(\"Year\")[\"Precision\"].idxmax()]\n",
    "\n",
    "    # Compute average precision and accuracy per model\n",
    "    avg_results = all_results.groupby(\"Model\")[[\"Accuracy\", \"Precision\"]].mean().reset_index()\n",
    "\n",
    "    # Find the best overall model based on highest average accuracy\n",
    "    best_model = avg_results.loc[avg_results[\"Accuracy\"].idxmax()]\n",
    "\n",
    "    # Find the best overall model based on highest average precision\n",
    "    best_precision_model = avg_results.loc[avg_results[\"Precision\"].idxmax()]\n",
    "\n",
    "    # Display results\n",
    "    print(\"Best Model Per Year (by Accuracy):\")\n",
    "    print(best_per_year)\n",
    "\n",
    "    print(\"\\nBest Model Per Year (by Precision):\")\n",
    "    print(best_per_year_precision)\n",
    "\n",
    "    print(\"\\nOverall Best Model (by Accuracy):\")\n",
    "    print(f\"Model: {best_model['Model']}, Avg Precision: {best_model['Precision']:.4f}, Avg Accuracy: {best_model['Accuracy']:.4f}\")\n",
    "\n",
    "    print(\"\\nOverall Best Model (by Precision):\")\n",
    "    print(f\"Model: {best_precision_model['Model']}, Avg Precision: {best_precision_model['Precision']:.4f}, Avg Accuracy: {best_precision_model['Accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1659e-c352-4f5f-a209-fa2acadc2749",
   "metadata": {},
   "source": [
    "## Models with Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f03d9f-d488-43b0-9970-42fe21338805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all models\n",
    "def best_basic_model_rolling(A, B):\n",
    "    KNN_results = make_yearly_predictions_knn_roll(A, B)\n",
    "    LDA_results =make_yearly_predictions_lda_roll(A, B)\n",
    "    LR_results = make_yearly_predictions_lr_roll(A, B)\n",
    "    QDA_results = make_yearly_predictions_qda_roll(A, B)\n",
    "\n",
    "    # Combine all results\n",
    "    all_results = pd.concat([KNN_results, LDA_results, LR_results, QDA_results], ignore_index=True)\n",
    "\n",
    "    # Find best accuracy & precision for each year\n",
    "    best_per_year = all_results.loc[all_results.groupby(\"Year\")[\"Accuracy\"].idxmax()]\n",
    "    best_per_year_precision = all_results.loc[all_results.groupby(\"Year\")[\"Precision\"].idxmax()]\n",
    "\n",
    "    # Compute average precision and accuracy per model\n",
    "    avg_results = all_results.groupby(\"Model\")[[\"Accuracy\", \"Precision\"]].mean().reset_index()\n",
    "\n",
    "    # Find the best overall model based on highest average accuracy\n",
    "    best_model = avg_results.loc[avg_results[\"Accuracy\"].idxmax()]\n",
    "\n",
    "    # Find the best overall model based on highest average precision\n",
    "    best_precision_model = avg_results.loc[avg_results[\"Precision\"].idxmax()]\n",
    "\n",
    "    # Display results\n",
    "    print(\"Best Model Per Year (by Accuracy):\")\n",
    "    print(best_per_year)\n",
    "\n",
    "    print(\"\\nBest Model Per Year (by Precision):\")\n",
    "    print(best_per_year_precision)\n",
    "\n",
    "    print(\"\\nOverall Best Model (by Accuracy):\")\n",
    "    print(f\"Model: {best_model['Model']}, Avg Precision: {best_model['Precision']:.4f}, Avg Accuracy: {best_model['Accuracy']:.4f}\")\n",
    "\n",
    "    print(\"\\nOverall Best Model (by Precision):\")\n",
    "    print(f\"Model: {best_precision_model['Model']}, Avg Precision: {best_precision_model['Precision']:.4f}, Avg Accuracy: {best_precision_model['Accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f3e95-a7d0-4567-9e94-94e2dec07da5",
   "metadata": {},
   "source": [
    "## Models with Full Set Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0314b749-0339-45e8-9cd5-790a86fa4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all models\n",
    "def best_basic_model_full(A, B):\n",
    "    KNN_results = make_yearly_predictions_knn_full(A, B)\n",
    "    LDA_results =make_yearly_predictions_lda_full(A, B)\n",
    "    LR_results = make_yearly_predictions_lr_full(A, B)\n",
    "    QDA_results = make_yearly_predictions_qda_full(A, B)\n",
    "\n",
    "    # Combine all results\n",
    "    all_results = pd.concat([KNN_results, LDA_results, LR_results, QDA_results], ignore_index=True)\n",
    "\n",
    "    # Find best accuracy & precision for each year\n",
    "    best_per_year = all_results.loc[all_results.groupby(\"Year\")[\"Accuracy\"].idxmax()]\n",
    "    best_per_year_precision = all_results.loc[all_results.groupby(\"Year\")[\"Precision\"].idxmax()]\n",
    "\n",
    "    # Compute average precision and accuracy per model\n",
    "    avg_results = all_results.groupby(\"Model\")[[\"Accuracy\", \"Precision\"]].mean().reset_index()\n",
    "\n",
    "    # Find the best overall model based on highest average accuracy\n",
    "    best_model = avg_results.loc[avg_results[\"Accuracy\"].idxmax()]\n",
    "\n",
    "    # Find the best overall model based on highest average precision\n",
    "    best_precision_model = avg_results.loc[avg_results[\"Precision\"].idxmax()]\n",
    "\n",
    "    # Display results\n",
    "    print(\"Best Model Per Year (by Accuracy):\")\n",
    "    print(best_per_year)\n",
    "\n",
    "    print(\"\\nBest Model Per Year (by Precision):\")\n",
    "    print(best_per_year_precision)\n",
    "\n",
    "    print(\"\\nOverall Best Model (by Accuracy):\")\n",
    "    print(f\"Model: {best_model['Model']}, Avg Precision: {best_model['Precision']:.4f}, Avg Accuracy: {best_model['Accuracy']:.4f}\")\n",
    "\n",
    "    print(\"\\nOverall Best Model (by Precision):\")\n",
    "    print(f\"Model: {best_precision_model['Model']}, Avg Precision: {best_precision_model['Precision']:.4f}, Avg Accuracy: {best_precision_model['Accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a6d6b-ca56-4ac8-9667-c68efd36bf40",
   "metadata": {},
   "source": [
    "## Importance of Training Accuracy \n",
    "\n",
    "Training accuracy measures how well a machine learning model fits the training data. It is important to check training accuracy for the following reasons:\n",
    "\n",
    "1. **Detecting Underfitting**  \n",
    "   - If the training accuracy is **too low**, it means the model is **not learning enough** patterns from the data.  \n",
    "   - This could be due to an **overly simple model**, insufficient features, or poor hyperparameters.\n",
    "\n",
    "2. **Ensuring Model Competency**  \n",
    "   - A model with **reasonable training accuracy** ensures that it has successfully learned meaningful patterns from the dataset.  \n",
    "   - If the model cannot achieve high accuracy on the training data, it is unlikely to perform well on new data.\n",
    "\n",
    "3. **Providing a Baseline for Comparison**  \n",
    "   - Training accuracy helps us **compare** with testing accuracy to detect **overfitting**.  \n",
    "   - If training accuracy is significantly higher than testing accuracy, the model might be **memorizing** rather than **generalizing**.\n",
    "\n",
    "ðŸ’¡ **Key Insight**: While high training accuracy is desirable, it should not be the sole indicator of a good model. We must also check testing accuracy to ensure real-world performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60522783-85a4-415a-b938-2b3bc6878e20",
   "metadata": {},
   "source": [
    "## Models with Baseline Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2e547-f338-443f-9cdb-c5026f7b63d6",
   "metadata": {},
   "source": [
    "## Models with Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f517650-f162-4e72-bcb1-d3bcf67e4b60",
   "metadata": {},
   "source": [
    "## Models with Full Set Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7649a-8ef2-427c-bf92-793d952a5e65",
   "metadata": {},
   "source": [
    "## Importance of Checking Testing Accuracy\n",
    "\n",
    "Testing accuracy measures how well a machine learning model performs on **unseen** data. It is crucial to check testing accuracy for the following reasons:\n",
    "\n",
    "1. **Evaluating Generalization**  \n",
    "   - The primary goal of machine learning is to create models that **generalize well** to new data.  \n",
    "   - A high testing accuracy indicates that the model can make reliable predictions on unseen samples.\n",
    "\n",
    "2. **Detecting Overfitting**  \n",
    "   - If the training accuracy is high but the testing accuracy is low, it suggests **overfitting**.  \n",
    "   - Overfitting occurs when the model learns **specific details** of the training data rather than general patterns, making it unreliable for new data.\n",
    "\n",
    "3. **Validating Model Performance**  \n",
    "   - A model is only useful if it performs well on real-world data.  \n",
    "   - Testing accuracy gives us a **realistic expectation** of how the model will behave when deployed.\n",
    "\n",
    "4. **Comparing Different Models**  \n",
    "   - By evaluating testing accuracy across different models, we can select the best model for **real-world applications**.  \n",
    "   - The model with the highest **testing accuracy and precision** is often the best choice.\n",
    "\n",
    "ðŸ’¡ **Key Insight**: A good model should have **both high training and testing accuracy**. A balance between these ensures that the model is neither too simple (underfitting) nor too complex (overfitting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990125d7-78f1-4f91-8757-3e5d32f332a2",
   "metadata": {},
   "source": [
    "## Models with Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3b18b9-41ff-4700-b2d4-4faa40f1db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_baseline(matches,test_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20723dec-fcf3-49f4-be25-4bffe47aebbf",
   "metadata": {},
   "source": [
    "## Models with Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "666a99f4-232b-4c81-b8e6-434e6c74b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_rolling(matches,test_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e4ef8-8ee1-4a1e-acd3-50e2aadd5bd3",
   "metadata": {},
   "source": [
    "## Models with Full Set Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68eb9c35-a276-4564-aff3-2e287a5bc55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_full(new_matches,new_test_matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
