{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc70686b-e030-4a77-8c0e-cfcba865da64",
   "metadata": {},
   "source": [
    "### **K-Nearest Neighbors (KNN) Classification**  \n",
    "\n",
    "K-Nearest Neighbors (KNN) is a simple, non-parametric classification algorithm that assigns a class to a data point based on the majority class of its nearest neighbors. It is widely used for classification and regression tasks due to its ease of implementation and intuitive approach.  \n",
    "\n",
    "### **How It Works:**  \n",
    "- **Instance-Based Learning**: KNN does not explicitly learn a model but stores the entire dataset and classifies new points based on proximity to existing data.  \n",
    "- **Distance Metric**: Computes the distance between points using metrics like **Euclidean distance**, **Manhattan distance**, or **Minkowski distance**.  \n",
    "- **Voting Mechanism**: Assigns a class based on the majority vote of the **k** nearest neighbors. A smaller **k** is more sensitive to noise, while a larger **k** smooths decision boundaries.  \n",
    "- **Weighted Voting (Optional)**: Some versions weight neighbors by distance, giving closer points more influence in classification.  \n",
    "\n",
    "### **Advantages:**  \n",
    "✅ **Simple & Intuitive**: Easy to understand and implement without making strong assumptions about data distribution.  \n",
    "✅ **Non-Parametric**: Works well with complex decision boundaries since it does not assume a specific functional form.  \n",
    "✅ **Handles Multi-Class Problems**: Naturally supports multiple classes without modification.  \n",
    "✅ **Adaptable to Different Distance Metrics**: Can be customized using different distance functions to suit various data types.  \n",
    "\n",
    "### **Disadvantages:**  \n",
    "❌ **Computationally Expensive**: Requires storing the entire dataset and computing distances at prediction time, making it slow for large datasets.  \n",
    "❌ **Sensitive to Irrelevant Features**: Performance degrades if irrelevant or redundant features dominate meaningful ones.  \n",
    "❌ **Imbalanced Classes Issue**: May favor majority classes unless weighting techniques are applied.  \n",
    "❌ **Curse of Dimensionality**: High-dimensional data can make distance calculations less meaningful, reducing effectiveness.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435f728-6654-4fd0-8e72-d8deb7dcdfb2",
   "metadata": {},
   "source": [
    "### KNN using Baseline Predictors (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e79954-582f-45fd-9f0a-f52f8b9db86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_knn_base(Train, Test):\n",
    "    # Define predictors\n",
    "    static_predictors = parameters_base(Train, Test)\n",
    "    best_k = find_best_k_base(Train)\n",
    "    \n",
    "    # Train a KNN model\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_clf.fit(Train[static_predictors], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = knn_clf.predict(test_year[static_predictors])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"K-Nearest Neighbors\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525616cf-bfef-44e3-9c3e-26feb0d37250",
   "metadata": {},
   "source": [
    "### KNN using Baseline Predictors + Rolling Predictors (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c53610-73a9-4e69-b753-4a895ca70548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_knn_roll(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "    best_k = find_best_k_roll(Train) \n",
    "    all_predictors = parameters_roll(Train,Test)\n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "      # Train a KNN model\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_clf.fit(Train[all_predictors], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = knn_clf.predict(test_year[all_predictors])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"K-Nearest Neighbors\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281f88e-8815-4ae5-9bc5-9c1c13aa33e1",
   "metadata": {},
   "source": [
    "### KNN using  Full Feature Set (refer /Data/Data_Formatting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2ac509-6e12-4c23-a9d1-ede300b8dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearly_predictions_knn_full(Train, Test):\n",
    "    # Convert 'Date' columns to datetime and sort data\n",
    "    best_k = find_best_k_full(Train) \n",
    "    all_predictors = parameters_full(Train,Test)\n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "      # Train a KNN model\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_clf.fit(Train[all_predictors], Train[\"Target\"])\n",
    "\n",
    "    results = []\n",
    "    for year in range(Test['Date'].dt.year.min(), Test['Date'].dt.year.max() + 1):\n",
    "        test_year = Test[Test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            # Predict on test data\n",
    "            preds = knn_clf.predict(test_year[all_predictors])\n",
    "\n",
    "            # Calculate precision and accuracy\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\", zero_division=1)\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "\n",
    "            # Append results to list\n",
    "            results.append({\n",
    "                \"Model\": \"K-Nearest Neighbors\",\n",
    "                \"Year\": year,\n",
    "                \"Precision\": precision,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
