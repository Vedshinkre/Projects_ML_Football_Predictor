{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc92b800-1eb8-4aeb-bdb2-a0e838d26afb",
   "metadata": {},
   "source": [
    "# üîß Understanding Hyperparameters in Machine Learning Models  \n",
    "\n",
    "## What Are Hyperparameters?  \n",
    "Hyperparameters are **configurable parameters** set before a machine learning model begins training. Unlike model parameters (e.g., weights in neural networks), hyperparameters **are not learned from the data** but are instead manually specified or optimized using techniques like **grid search** or **random search**.  \n",
    "\n",
    "## Why Do We Need Hyperparameters?  \n",
    "Hyperparameters play a crucial role in determining the **performance, speed, and generalization** of a model. Choosing the right hyperparameters can:  \n",
    "- Improve **accuracy** and **efficiency**  \n",
    "- Prevent **overfitting** (learning noise instead of patterns)  \n",
    "- Enhance **generalization** to unseen data  \n",
    "- Speed up **training and inference**  \n",
    "\n",
    "## Examples of Hyperparameters in Different Models  \n",
    "Here are some common hyperparameters across different models:  \n",
    "\n",
    "### üèÜ Decision Trees & Random Forests  \n",
    "- `max_depth`: Controls tree depth to prevent overfitting  \n",
    "- `min_samples_split`: Minimum samples required to split a node  \n",
    "- `n_estimators` (for ensembles): Number of trees in a forest  \n",
    "\n",
    "### üî• Neural Networks  \n",
    "- `learning_rate`: Defines how fast the model updates weights  \n",
    "- `batch_size`: Number of training samples per batch  \n",
    "- `epochs`: Number of complete passes through the dataset  \n",
    "\n",
    "### üìà Gradient Boosting (XGBoost, LightGBM)  \n",
    "- `learning_rate`: Controls the contribution of each tree  \n",
    "- `n_estimators`: Number of boosting rounds  \n",
    "- `max_depth`: Limits tree depth to prevent overfitting  \n",
    "\n",
    "## What Is the \"Perfect\" Hyperparameter Value?  \n",
    "There is **no universal perfect value** for hyperparameters. The optimal settings depend on:  \n",
    "- The **dataset** size and complexity  \n",
    "- The **model type** and architecture  \n",
    "- The **goal** (e.g., maximizing accuracy vs. minimizing inference time)  \n",
    "\n",
    "To find the best hyperparameters, we use:  \n",
    "‚úÖ **Grid Search**: Tests all combinations of hyperparameters  \n",
    "‚úÖ **Random Search**: Randomly samples hyperparameters for efficiency  \n",
    "‚úÖ **Bayesian Optimization**: Selects hyperparameters based on past results  \n",
    "\n",
    "## üîç Conclusion  \n",
    "Hyperparameters **define how a model learns**, impacting its **accuracy, speed, and generalization**. Proper tuning is essential for achieving **optimal performance** without overfitting or underfitting.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb0ab5-d885-41a3-8c5d-7c98b5d9ea7f",
   "metadata": {},
   "source": [
    "## **1. Pruning in Classification Tree**  \n",
    "Pruning helps prevent **overfitting** by reducing the size of a decision tree, leading to improved accuracy on unseen data. Without pruning, a tree may **memorize** training data rather than generalizing well to new data.  \n",
    "\n",
    "### **Post-Pruning (Cost Complexity Pruning - CCP)**  \n",
    "In post-pruning, the tree is first grown to full depth (even if it overfits) and then gradually pruned by removing nodes based on a complexity parameter Œ± .  \n",
    "\n",
    "#### **How CCP Works?**  \n",
    "The pruning process minimizes the following equation:  \n",
    "\n",
    "$$\n",
    "\\text{Total Cost} = \\text{RSS} + \\alpha \\times \\text{Number of Leaves}\n",
    "$$\n",
    "\n",
    "\n",
    "- **RSS (Residual Sum of Squares)** measures the error in predictions.  \n",
    "- **Œ±** is a tuning parameter that controls the trade-off between tree complexity and error.  \n",
    "  - **Higher Œ±** ‚Üí More pruning ‚Üí Simpler tree.  \n",
    "  - **Lower Œ±** ‚Üí Less pruning ‚Üí More complex tree.  \n",
    "- The value for **Œ±** can be found using cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d76a23-faf7-4fa8-98cb-759c2e9e1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run Parameters.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb1f04-d6e1-41b9-99d0-4cdae0cddf63",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6af1ad02-94c3-4e14-9318-81044475fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find optimal ccp_alpha\n",
    "def find_optimal_alpha_base(Train):\n",
    "    static_predictors = cv_parameters_base(Train)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    path = dt.cost_complexity_pruning_path(Train[static_predictors], Train[\"Target\"])\n",
    "    ccp_alphas = path.ccp_alphas[:-1]  # Exclude the last value to avoid a single-node tree\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    alpha_scores = {}\n",
    "    \n",
    "    for alpha in ccp_alphas:\n",
    "        dt = DecisionTreeClassifier(random_state=1, ccp_alpha=alpha)\n",
    "        scores = cross_val_score(dt, Train[static_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        alpha_scores[alpha] = np.mean(scores)\n",
    "    \n",
    "    best_alpha = max(alpha_scores, key=alpha_scores.get)\n",
    "    print(f\"Best ccp_alpha: {best_alpha:.6f} with Accuracy: {alpha_scores[best_alpha]:.4f}\")\n",
    "    return best_alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab7979-3e48-4ea9-a8d8-8d914516894a",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "217931f9-a492-47c7-b063-f8c129b93288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find optimal ccp_alpha\n",
    "def find_optimal_alpha_roll(Train):\n",
    "\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    path = dt.cost_complexity_pruning_path(Train[all_predictors], Train[\"Target\"])\n",
    "    ccp_alphas = path.ccp_alphas[:-1]  # Exclude the last value to avoid a single-node tree\n",
    "\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    alpha_scores = {}\n",
    "    \n",
    "    for alpha in ccp_alphas:\n",
    "        dt = DecisionTreeClassifier(random_state=1, ccp_alpha=alpha)\n",
    "        scores = cross_val_score(dt, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        alpha_scores[alpha] = np.mean(scores)\n",
    "    \n",
    "    best_alpha = max(alpha_scores, key=alpha_scores.get)\n",
    "    print(f\"Best ccp_alpha: {best_alpha:.6f} with Accuracy: {alpha_scores[best_alpha]:.4f}\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78fa67-0670-4eb6-ad2a-d08bd555028a",
   "metadata": {},
   "source": [
    " ### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2640862-1f0f-4c5b-a43e-cfdcb015cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find optimal ccp_alpha\n",
    "def find_optimal_alpha_full(Train):\n",
    "        # Define the feature columns for which we'll calculate rolling averages\n",
    "    all_predictors = cv_parameters_full(Train)\n",
    "    Train = roll(Train)\n",
    "\n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    path = dt.cost_complexity_pruning_path(Train[all_predictors], Train[\"Target\"])\n",
    "    ccp_alphas = path.ccp_alphas[:-1]  # Exclude the last value to avoid a single-node tree\n",
    " \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    alpha_scores = {}\n",
    "    \n",
    "    for alpha in ccp_alphas:\n",
    "        dt = DecisionTreeClassifier(random_state=1, ccp_alpha=alpha)\n",
    "        scores = cross_val_score(dt, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        alpha_scores[alpha] = np.mean(scores)\n",
    "    \n",
    "    best_alpha = max(alpha_scores, key=alpha_scores.get)\n",
    "    print(f\"Best ccp_alpha: {best_alpha:.6f} with Accuracy: {alpha_scores[best_alpha]:.4f}\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591f15f-b367-49c8-9389-59833539e72d",
   "metadata": {},
   "source": [
    "## **2. C in Logistic Regression**  \n",
    "In **Logistic Regression**, `C` is the **inverse of the regularization strength** (also called the **inverse of lambda** in regularization).\n",
    "\n",
    "$$ \n",
    "C = \\frac{1}{\\lambda}\n",
    "$$\n",
    "where **Œª (lambda)** is the regularization parameter.\n",
    "\n",
    "### üîπ What Does `C` Do?\n",
    "- It **controls the trade-off** between model complexity and generalization.\n",
    "- **Higher values of `C`** ‚Üí Less regularization (**more complex model, risk of overfitting**).\n",
    "- **Lower values of `C`** ‚Üí More regularization (**simpler model, avoids overfitting**).\n",
    "\n",
    "### üîπ Impact of `C` Values\n",
    "\n",
    "| `C` Value  | Effect on Model |\n",
    "|------------|---------------|\n",
    "| **Very Small (`C ‚Üí 0.0001`)** | Strong regularization, may underfit |\n",
    "| **Moderate (`C = 1.0`)** | Balanced regularization |\n",
    "| **Very Large (`C ‚Üí 10000`)** | Almost no regularization, may overfit |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb958025-448d-4cef-9ffb-937d563adbf2",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "881ccfdb-be3e-4c48-bb41-e9b0ba65d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal C for Logistic Regression\n",
    "def find_optimal_C_base(Train):\n",
    "    static_predictors = cv_parameters_base(Train)\n",
    "\n",
    "    # Define a range of C values to test (logarithmically spaced)\n",
    "    C_values = np.logspace(-2, 3, 20)   # Testing C from 0.0001 to 10000\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    C_scores = {}\n",
    "\n",
    "    for C in C_values:\n",
    "        lr = LogisticRegression(C=C, solver='liblinear', random_state=1)\n",
    "        scores = cross_val_score(lr, Train[static_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        C_scores[C] = np.mean(scores)\n",
    "\n",
    "    best_C = max(C_scores, key=C_scores.get)\n",
    "    print(f\"Best C: {best_C:.6f} with Accuracy: {C_scores[best_C]:.4f}\")\n",
    "    return best_C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbad8da-4de2-4781-b1b4-88fd48ffedcb",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f1619ad-2d4d-42cd-9abc-6322a33dbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal C for Logistic Regression\n",
    "def find_optimal_C_roll(Train):\n",
    "   # Define the feature columns for which we'll calculate rolling averages\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    "\n",
    "    # Define a range of C values to test (logarithmically spaced)\n",
    "    C_values = np.logspace(-2, 3, 20)   # Testing C from 0.0001 to 10000\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    C_scores = {}\n",
    "\n",
    "    for C in C_values:\n",
    "        lr = LogisticRegression(C=C, solver='liblinear', random_state=1)\n",
    "        scores = cross_val_score(lr, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        C_scores[C] = np.mean(scores)\n",
    "\n",
    "    best_C = max(C_scores, key=C_scores.get)\n",
    "    print(f\"Best C: {best_C:.6f} with Accuracy: {C_scores[best_C]:.4f}\")\n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4fc91-641e-4cb3-941d-c309c70d688d",
   "metadata": {},
   "source": [
    " ### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcffa8f4-9702-43fa-a8f3-5b86a7ab4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal C for Logistic Regression\n",
    "def find_optimal_C_full(Train):\n",
    "   # Define the feature columns for which we'll calculate rolling averages\n",
    "    all_predictors = cv_parameters_full(Train)\n",
    "    Train = roll(Train)\n",
    "    # Define a range of C values to test (logarithmically spaced)\n",
    "    C_values = np.logspace(-2, 3, 20)   # Testing C from 0.0001 to 10000\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    C_scores = {}\n",
    "\n",
    "    for C in C_values:\n",
    "        lr = LogisticRegression(C=C, solver='liblinear', random_state=1)\n",
    "        scores = cross_val_score(lr, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        C_scores[C] = np.mean(scores)\n",
    "\n",
    "    best_C = max(C_scores, key=C_scores.get)\n",
    "    print(f\"Best C: {best_C:.6f} with Accuracy: {C_scores[best_C]:.4f}\")\n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0ee13-1a59-4655-b8f7-d06d503f8e0e",
   "metadata": {},
   "source": [
    "# LDA Shrinkage\n",
    "## What is Shrinkage in LDA?\n",
    "Shrinkage is a regularization technique used in **Linear Discriminant Analysis (LDA)** to improve the estimation of the covariance matrix. It blends the empirical covariance matrix with a more structured version, reducing overfitting and improving stability, especially when dealing with high-dimensional data.\n",
    "\n",
    "## When and Why is Shrinkage Needed?\n",
    "- When **the number of features is large** compared to the number of samples, the empirical covariance matrix can be poorly estimated.\n",
    "- Shrinkage **adds regularization** to avoid overfitting and makes the model more robust.\n",
    "- It is useful when **the covariance matrix is nearly singular or unstable**.\n",
    "- Works **only with `solver=\"lsqr\"` or `solver=\"eigen\"`**, as these solvers allow regularization.\n",
    "\n",
    "## How is Shrinkage Controlled?\n",
    "The shrinkage parameter (`shrinkage`) is a value between **0 and 1**:\n",
    "- `shrinkage=0`: No shrinkage (uses the empirical covariance matrix).\n",
    "- `shrinkage=1`: Full shrinkage (uses a diagonalized covariance matrix).\n",
    "- **Optimal values** can be found via cross-validation (`GridSearchCV`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a011b-3a27-491e-86e1-d983580d902b",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "436fb53e-09bc-4ec5-a13b-b488ba0814ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_shrinkage_base(Train):\n",
    "    static_predictors = cv_parameters_base(Train)\n",
    "    param_grid ={\"shrinkage\": np.linspace(0.0, 1.0, 10)}\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"lsqr\")\n",
    "    grid_search = GridSearchCV(lda, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "    return grid_search.best_params_[\"shrinkage\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05853a2a-d0b3-4000-95f1-0d0c87078896",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98705229-462d-441a-8cda-2e220b4c3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_shrinkage_roll(Train):\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    "\n",
    "    param_grid = {\"shrinkage\": np.linspace(0.0, 1.0, 10)}\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"lsqr\")\n",
    "    grid_search = GridSearchCV(lda, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "    return grid_search.best_params_[\"shrinkage\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8573c-073c-4787-ab6d-4e4532236eef",
   "metadata": {},
   "source": [
    " ### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d398db6-4a38-4885-9b32-ac0218cf89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_shrinkage_full(Train):\n",
    "     # Define the feature columns for which we'll calculate rolling averages\n",
    "    all_predictors = cv_parameters_full(Train)\n",
    "    Train = roll(Train)\n",
    "\n",
    "    param_grid = {\"shrinkage\": np.linspace(0.0, 1.0, 10)}\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"lsqr\")\n",
    "    grid_search = GridSearchCV(lda, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "    return grid_search.best_params_[\"shrinkage\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993d979-b44a-48e3-ad46-8ba5ad6e7d39",
   "metadata": {},
   "source": [
    "## Choosing the Best k in K-Nearest Neighbors (KNN)\n",
    "\n",
    "### What is k in KNN?\n",
    "In K-Nearest Neighbors (KNN), **k** represents the number of nearest data points used to classify a new instance. Choosing the right **k** value is crucial for balancing bias and variance in the model.\n",
    "\n",
    "### Why Do We Need to Find the Best k?\n",
    "Finding the optimal **k** is essential because:\n",
    "\n",
    "- **Too Small k (e.g., k=1-3)**  \n",
    "  - The model is **highly sensitive** to noise and outliers.  \n",
    "  - Leads to **high variance**, meaning the model overfits the training data.  \n",
    "  - Predictions can be unstable with slight changes in data.  \n",
    "\n",
    "- **Too Large k (e.g., k > 20)**  \n",
    "  - The model becomes **too smooth** and may **underfit** the data.  \n",
    "  - Reduces sensitivity to individual data points, which can decrease accuracy.  \n",
    "  - Can bias predictions toward the majority class in imbalanced datasets.  \n",
    "\n",
    "### How to Find the Best k?\n",
    "To find the optimal **k**, we use **cross-validation** (e.g., GridSearchCV) by testing multiple values of **k** and selecting the one that provides the highest accuracy.\n",
    "\n",
    "### Key Takeaways:\n",
    "‚úÖ **A balanced k-value** prevents both overfitting (high variance) and underfitting (high bias).  \n",
    "‚úÖ **Cross-validation** helps choose the best k without relying on a single dataset split.  \n",
    "‚úÖ **Typically, k is an odd number** to avoid ties in binary classification.  \n",
    "‚úÖ **The best k varies per dataset** and should always be determined experimentally.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c83de-4dd4-4ab7-b569-e28a7d7f3ac1",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59371124-c8a8-4dec-bfbb-2914ec7e27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_base(Train):\n",
    "    static_predictors = cv_parameters_base(Train)\n",
    "    \n",
    "    # Define parameter grid for k values (searching between 1 and 20)\n",
    "    param_grid = {\"n_neighbors\": np.arange(1, 21)}\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(knn, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "    \n",
    "    return grid_search.best_params_[\"n_neighbors\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c8fb3-16ca-4ec8-83dd-a4c2426ddb07",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9303804-5b58-47c4-aae2-34fac13c1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_roll(Train):\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    " \n",
    "    # Define parameter grid for k values (searching between 1 and 20)\n",
    "    param_grid = {\"n_neighbors\": np.arange(1, 21)}\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(knn, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "    \n",
    "    return grid_search.best_params_[\"n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242f5e1-969d-44bb-8114-07df6131d4dc",
   "metadata": {},
   "source": [
    " ### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3636b02-0e31-4b93-9ca1-97eaa056738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k_full(Train):\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    all_predictors = cv_parameters_full(Train)\n",
    "    Train = roll(Train)\n",
    "\n",
    "    \n",
    "    # Define parameter grid for k values (searching between 1 and 20)\n",
    "    param_grid = {\"n_neighbors\": np.arange(1, 21)}\n",
    "    \n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(knn, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "    \n",
    "    return grid_search.best_params_[\"n_neighbors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d93a78-20c5-424f-9442-a5bcddd4f48a",
   "metadata": {},
   "source": [
    "## **What is C in Support Vector Machines (SVM)?**  \n",
    "\n",
    "In **Support Vector Machines (SVMs)**, the **C parameter** (regularization parameter) controls the trade-off between maximizing the margin and minimizing classification errors. It determines how much **misclassification is tolerated** when finding the optimal hyperplane.  \n",
    "\n",
    "### **How C Affects the Model:**  \n",
    "- **High C (Hard Margin SVM)**:  \n",
    "  - Enforces strict classification with fewer misclassified points.  \n",
    "  - Leads to a **smaller margin** and may **overfit** the training data.  \n",
    "  - Sensitive to noise and outliers.  \n",
    "\n",
    "- **Low C (Soft Margin SVM)**:  \n",
    "  - Allows some misclassification for better generalization.  \n",
    "  - Leads to a **larger margin** and helps **avoid overfitting**.  \n",
    "  - More robust to noisy data.  \n",
    "\n",
    "### **Why Do We Need to Find the Best C?**  \n",
    "Choosing an inappropriate **C** can significantly affect model performance:  \n",
    "‚úÖ **Too High ‚Üí Overfitting**: The model memorizes the training data but may fail on unseen data.  \n",
    "‚úÖ **Too Low ‚Üí Underfitting**: The model allows too many misclassifications, reducing accuracy.  \n",
    "‚úÖ **Optimal C ‚Üí Best Trade-off**: Finding the right **C** ensures the model generalizes well to new data.  \n",
    "\n",
    "### **How to Find the Best C?**  \n",
    "We use **cross-validation** (e.g., **GridSearchCV**) to test multiple values of **C** and select the one that gives the highest accuracy on validation data. This ensures the model performs well on both training and unseen data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91164ee2-64db-4f5b-9da9-51fe383c646f",
   "metadata": {},
   "source": [
    "### Baseline Predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23a30409-ebe7-462a-a6a0-cbbae81933ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def best_c_base_linear(Train):\n",
    "    static_predictors = cv_parameters_base(Train)\n",
    "    \n",
    "    # Define parameter grid for C values (searching in log scale between 0.001 and 1000)\n",
    "    param_grid = {\"C\": np.logspace(-3, 3, 10)}  \n",
    "    \n",
    "    svm = SVC(kernel=\"linear\")  # Using a linear kernel\n",
    "    \n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "    \n",
    "    return grid_search.best_params_[\"C\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800444a1-3ed4-46cc-9f6f-0f031204740b",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4e9a97c-623c-42bf-92b5-ce30dae0dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def best_c_roll_linear(Train):\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    "    # Define parameter grid for C values (searching in log scale between 0.001 and 1000)\n",
    "    param_grid = {\"C\": np.logspace(-3, 3, 10)}  \n",
    "    \n",
    "    svm = SVC(kernel=\"linear\")  # Using a linear kernel\n",
    "    \n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "    \n",
    "    return grid_search.best_params_[\"C\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e67d73-4af2-43d3-8872-b2fa4033c679",
   "metadata": {},
   "source": [
    "### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94638110-4d4e-4e1e-8a7f-a554185e15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def best_c_full_linear(Train):\n",
    "    all_predictors = cv_parameters_full(Train)\n",
    "    Train = roll(Train)\n",
    "    \n",
    "    # Define parameter grid for C values (searching in log scale between 0.001 and 1000)\n",
    "    param_grid = {\"C\": np.logspace(-3, 3, 10)}  \n",
    "    \n",
    "    svm = SVC(kernel=\"linear\")  # Using a linear kernel\n",
    "    \n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "    \n",
    "    return grid_search.best_params_[\"C\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971a64e-21fd-4c1f-89df-fadbda79cfba",
   "metadata": {},
   "source": [
    "## **What is the Degree \\( d \\) in a Polynomial Kernel for SVM?**  \n",
    "\n",
    "In **Support Vector Machines (SVMs)** with a **polynomial kernel**, the **degree \\( d \\)** determines the complexity of the decision boundary. The polynomial kernel is defined as:  \n",
    "\n",
    "$$\n",
    "K(x, y) = (x \\cdot y + c)^d\n",
    "$$\n",
    "\n",
    "where \\( d \\) is the **degree of the polynomial**, and **higher degrees** create more complex decision boundaries.\n",
    "\n",
    "### **How the Degree \\( d \\) Affects the Model:**  \n",
    "- **Low Degree (e.g., \\( d = 2 \\))** ‚Üí Creates **simpler decision boundaries** and reduces the risk of overfitting.  \n",
    "- **High Degree (e.g., \\( d = 5 \\) or more)** ‚Üí Allows **complex decision boundaries** but can lead to overfitting.  \n",
    "- **Very High Degree (\\( d \\gg 5 \\))** ‚Üí Can make the model too flexible, capturing noise instead of meaningful patterns.\n",
    "\n",
    "### **Why Do We Need to Find the Best Degree \\( d \\)?**  \n",
    "‚úÖ **Too Low \\( d \\) ‚Üí Underfitting**: The model may not capture the true structure of the data.  \n",
    "‚úÖ **Too High \\( d \\) ‚Üí Overfitting**: The model may memorize training data but fail on new data.  \n",
    "‚úÖ **Optimal \\( d \\) ‚Üí Best Generalization**: A well-chosen degree balances flexibility and robustness, leading to good performance on unseen data.\n",
    "\n",
    "### **How to Find the Best \\( d \\)?**  \n",
    "We use **cross-validation** (e.g., **GridSearchCV**) to test multiple values of \\( d \\) and find the one that provides the best accuracy. This ensures that the model generalizes well rather than just fitting the training data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0a47f-c6bd-4105-9811-8cd5ab81bd04",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a03dc6e-55e1-4978-8f2d-a2194742f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_d_base(Train):\n",
    "    static_predictors =  cv_parameters_base(Train)\n",
    "   \n",
    "    # Define parameter grid for polynomial degree (testing degrees 2 to 5) and C values\n",
    "    param_grid = {\n",
    "        \"C\": np.logspace(-3, 3, 5),  # Testing C values from 0.001 to 1000\n",
    "        \"degree\": [2, 3, 4, 5]  # Testing polynomial degrees 2 to 5\n",
    "    }\n",
    "    \n",
    "    svm = SVC(kernel=\"poly\")  # Use polynomial kernel\n",
    "    results = []\n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "\n",
    "    # Extract best C and degree\n",
    "    best_C = grid_search.best_params_[\"C\"]\n",
    "    best_d = grid_search.best_params_[\"degree\"]\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    results_df = pd.DataFrame([{\"C\": best_C, \"degree\": best_d}])\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ddae10-eee6-4e39-8d1e-ce1722c24869",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65aba306-dcba-423d-8329-dc932c8d6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_d_roll(Train):\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    "   \n",
    "    # Define parameter grid for polynomial degree (testing degrees 2 to 5) and C values\n",
    "    param_grid = {\n",
    "        \"C\": np.logspace(-3, 3, 5),  # Testing C values from 0.001 to 1000\n",
    "        \"degree\": [2, 3, 4, 5]  # Testing polynomial degrees 2 to 5\n",
    "    }\n",
    "    \n",
    "    svm = SVC(kernel=\"poly\")  # Use polynomial kernel\n",
    "    results = []\n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "\n",
    "    # Extract best C and degree\n",
    "    best_C = grid_search.best_params_[\"C\"]\n",
    "    best_d = grid_search.best_params_[\"degree\"]\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    results_df = pd.DataFrame([{\"C\": best_C, \"degree\": best_d}])\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b44c49-2773-45a9-98d7-c144f96f3cae",
   "metadata": {},
   "source": [
    "### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bcf4b613-c845-4eee-9b85-fdc3a6c1a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_d_full(Train):\n",
    "    all_predictors = cv_parameters_full(Train)\n",
    "    Train = roll(Train)\n",
    "    # Define parameter grid for polynomial degree (testing degrees 2 to 5) and C values\n",
    "    param_grid = {\n",
    "        \"C\": np.logspace(-3, 3, 5),  # Testing C values from 0.001 to 1000\n",
    "        \"degree\": [2, 3, 4, 5]  # Testing polynomial degrees 2 to 5\n",
    "    }\n",
    "    \n",
    "    svm = SVC(kernel=\"poly\")  # Use polynomial kernel\n",
    "    results = []\n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "\n",
    "    # Extract best C and degree\n",
    "    best_C = grid_search.best_params_[\"C\"]\n",
    "    best_d = grid_search.best_params_[\"degree\"]\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    results_df = pd.DataFrame([{\"C\": best_C, \"degree\": best_d}])\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9d580-5e60-4f93-b5d6-f78dbe052352",
   "metadata": {},
   "source": [
    "## **Gamma (Œ≥) in Support Vector Machines (SVM)**  \n",
    "\n",
    "## **What is Gamma (Œ≥)?**  \n",
    "Gamma (Œ≥) is a hyperparameter used in the **Radial Basis Function (RBF) kernel** of Support Vector Machines (SVM). It controls how far the influence of a single training example reaches, affecting the **complexity** of the decision boundary.  \n",
    "\n",
    "## **How Does Gamma Work?**  \n",
    "- A **small Œ≥ (e.g., 0.001)** means **far-reaching** influence, leading to a **smoother decision boundary** (more generalized model).  \n",
    "- A **large Œ≥ (e.g., 100)** means **short-range** influence, causing the model to **memorize the training data** and potentially overfit.  \n",
    "\n",
    "### **Effect of Gamma on Decision Boundary**  \n",
    "| Gamma (Œ≥) Value | Model Behavior |\n",
    "|---------------|---------------|\n",
    "| **Low (e.g., 0.001)** | Simpler decision boundary, may underfit |\n",
    "| **Medium (e.g., 1.0)** | Balanced generalization and flexibility |\n",
    "| **High (e.g., 100)** | Complex decision boundary, may overfit |\n",
    "\n",
    "## **Why is Finding the Best Gamma Important?**  \n",
    "- **Too small Œ≥** ‚Üí The model is too simple, leading to high bias and **underfitting**.  \n",
    "- **Too large Œ≥** ‚Üí The model is too complex, leading to high variance and **overfitting**.  \n",
    "- **Optimal Œ≥** ‚Üí Balances generalization and complexity, leading to **better performance on unseen data**.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e21581-dd05-4bec-87d5-9f6bfd13d1c7",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "543c434e-3cec-4bc1-a33b-5ba89942f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_g_base(Train):\n",
    "    static_predictors = cv_parameters_base(Train)\n",
    "\n",
    "    # Define parameter grid for C and gamma (for RBF)\n",
    "    param_grid = {\n",
    "        \"C\": np.logspace(-3, 3, 5),  # C values from 0.001 to 1000\n",
    "        \"gamma\": np.logspace(-3, 3, 5)  # Gamma values from 0.001 to 1000\n",
    "    }\n",
    "\n",
    "    svm = SVC(kernel=\"rbf\")  # Use RBF kernel\n",
    "\n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "\n",
    "    # Extract best C and gamma\n",
    "    best_C = grid_search.best_params_[\"C\"]\n",
    "    best_gamma = grid_search.best_params_[\"gamma\"]\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    results_df = pd.DataFrame([{\"C\": best_C, \"gamma\": best_gamma}])\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2645273-70c8-44a5-a470-8088457c725e",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e740724a-a015-46cc-87b8-35e6a1dc90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_g_roll(Train):\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    "\n",
    "    # Define parameter grid for C and gamma (for RBF)\n",
    "    param_grid = {\n",
    "        \"C\": np.logspace(-3, 3, 5),  # C values from 0.001 to 1000\n",
    "        \"gamma\": np.logspace(-3, 3, 5)  # Gamma values from 0.001 to 1000\n",
    "    }\n",
    "\n",
    "    svm = SVC(kernel=\"rbf\")  # Use RBF kernel\n",
    "\n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "\n",
    "    # Extract best C and gamma\n",
    "    best_C = grid_search.best_params_[\"C\"]\n",
    "    best_gamma = grid_search.best_params_[\"gamma\"]\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    results_df = pd.DataFrame([{\"C\": best_C, \"gamma\": best_gamma}])\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5d889-63bc-47c0-9f10-08d424d90dfa",
   "metadata": {},
   "source": [
    "### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7eeeff0e-b8f6-415d-9de3-869d0d4248d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_g_full(Train):\n",
    "    all_predictors = cv_parameters_full(Train)\n",
    "    Train = roll(Train)\n",
    "\n",
    "    # Define parameter grid for C and gamma (for RBF)\n",
    "    param_grid = {\n",
    "        \"C\": np.logspace(-3, 3, 5),  # C values from 0.001 to 1000\n",
    "        \"gamma\": np.logspace(-3, 3, 5)  # Gamma values from 0.001 to 1000\n",
    "    }\n",
    "\n",
    "    svm = SVC(kernel=\"rbf\")  # Use RBF kernel\n",
    "\n",
    "    # Perform GridSearchCV with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "\n",
    "    # Extract best C and gamma\n",
    "    best_C = grid_search.best_params_[\"C\"]\n",
    "    best_gamma = grid_search.best_params_[\"gamma\"]\n",
    "\n",
    "    # Store results in a DataFrame\n",
    "    results_df = pd.DataFrame([{\"C\": best_C, \"gamma\": best_gamma}])\n",
    "\n",
    "    return results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
