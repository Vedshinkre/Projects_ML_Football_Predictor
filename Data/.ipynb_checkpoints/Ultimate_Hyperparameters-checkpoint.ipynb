{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc92b800-1eb8-4aeb-bdb2-a0e838d26afb",
   "metadata": {},
   "source": [
    "# üîß Understanding Hyperparameters in Machine Learning Models  \n",
    "\n",
    "## What Are Hyperparameters?  \n",
    "Hyperparameters are **configurable parameters** set before a machine learning model begins training. Unlike model parameters (e.g., weights in neural networks), hyperparameters **are not learned from the data** but are instead manually specified or optimized using techniques like **grid search** or **random search**.  \n",
    "\n",
    "## Why Do We Need Hyperparameters?  \n",
    "Hyperparameters play a crucial role in determining the **performance, speed, and generalization** of a model. Choosing the right hyperparameters can:  \n",
    "- Improve **accuracy** and **efficiency**  \n",
    "- Prevent **overfitting** (learning noise instead of patterns)  \n",
    "- Enhance **generalization** to unseen data  \n",
    "- Speed up **training and inference**  \n",
    "\n",
    "## Examples of Hyperparameters in Different Models  \n",
    "Here are some common hyperparameters across different models:  \n",
    "\n",
    "### üèÜ Decision Trees & Random Forests  \n",
    "- `max_depth`: Controls tree depth to prevent overfitting  \n",
    "- `min_samples_split`: Minimum samples required to split a node  \n",
    "- `n_estimators` (for ensembles): Number of trees in a forest  \n",
    "\n",
    "### üî• Neural Networks  \n",
    "- `learning_rate`: Defines how fast the model updates weights  \n",
    "- `batch_size`: Number of training samples per batch  \n",
    "- `epochs`: Number of complete passes through the dataset  \n",
    "\n",
    "### üìà Gradient Boosting (XGBoost, LightGBM)  \n",
    "- `learning_rate`: Controls the contribution of each tree  \n",
    "- `n_estimators`: Number of boosting rounds  \n",
    "- `max_depth`: Limits tree depth to prevent overfitting  \n",
    "\n",
    "## What Is the \"Perfect\" Hyperparameter Value?  \n",
    "There is **no universal perfect value** for hyperparameters. The optimal settings depend on:  \n",
    "- The **dataset** size and complexity  \n",
    "- The **model type** and architecture  \n",
    "- The **goal** (e.g., maximizing accuracy vs. minimizing inference time)  \n",
    "\n",
    "To find the best hyperparameters, we use:  \n",
    "‚úÖ **Grid Search**: Tests all combinations of hyperparameters  \n",
    "‚úÖ **Random Search**: Randomly samples hyperparameters for efficiency  \n",
    "‚úÖ **Bayesian Optimization**: Selects hyperparameters based on past results  \n",
    "\n",
    "## üîç Conclusion  \n",
    "Hyperparameters **define how a model learns**, impacting its **accuracy, speed, and generalization**. Proper tuning is essential for achieving **optimal performance** without overfitting or underfitting.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb0ab5-d885-41a3-8c5d-7c98b5d9ea7f",
   "metadata": {},
   "source": [
    "## **1. Pruning in Classification Tree**  \n",
    "Pruning helps prevent **overfitting** by reducing the size of a decision tree, leading to improved accuracy on unseen data. Without pruning, a tree may **memorize** training data rather than generalizing well to new data.  \n",
    "\n",
    "### **Post-Pruning (Cost Complexity Pruning - CCP)**  \n",
    "In post-pruning, the tree is first grown to full depth (even if it overfits) and then gradually pruned by removing nodes based on a complexity parameter Œ± .  \n",
    "\n",
    "#### **How CCP Works?**  \n",
    "The pruning process minimizes the following equation:  \n",
    "\n",
    "$$\n",
    "\\text{Total Cost} = \\text{RSS} + \\alpha \\times \\text{Number of Leaves}\n",
    "$$\n",
    "\n",
    "\n",
    "- **RSS (Residual Sum of Squares)** measures the error in predictions.  \n",
    "- **Œ±** is a tuning parameter that controls the trade-off between tree complexity and error.  \n",
    "  - **Higher Œ±** ‚Üí More pruning ‚Üí Simpler tree.  \n",
    "  - **Lower Œ±** ‚Üí Less pruning ‚Üí More complex tree.  \n",
    "- The value for **Œ±** can be found using cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb1f04-d6e1-41b9-99d0-4cdae0cddf63",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6af1ad02-94c3-4e14-9318-81044475fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find optimal ccp_alpha\n",
    "def find_optimal_alpha_base(Train):\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    path = dt.cost_complexity_pruning_path(Train[static_predictors], Train[\"Target\"])\n",
    "    ccp_alphas = path.ccp_alphas[:-1]  # Exclude the last value to avoid a single-node tree\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    alpha_scores = {}\n",
    "    \n",
    "    for alpha in ccp_alphas:\n",
    "        dt = DecisionTreeClassifier(random_state=1, ccp_alpha=alpha)\n",
    "        scores = cross_val_score(dt, Train[static_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        alpha_scores[alpha] = np.mean(scores)\n",
    "    \n",
    "    best_alpha = max(alpha_scores, key=alpha_scores.get)\n",
    "    print(f\"Best ccp_alpha: {best_alpha:.6f} with Accuracy: {alpha_scores[best_alpha]:.4f}\")\n",
    "    return best_alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab7979-3e48-4ea9-a8d8-8d914516894a",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217931f9-a492-47c7-b063-f8c129b93288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find optimal ccp_alpha\n",
    "def find_optimal_alpha_roll(Train):\n",
    "\n",
    "    all_predictors = cv_parameters_roll(Train)\n",
    "    Train = roll(Train)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    path = dt.cost_complexity_pruning_path(Train[all_predictors], Train[\"Target\"])\n",
    "    ccp_alphas = path.ccp_alphas[:-1]  # Exclude the last value to avoid a single-node tree\n",
    "\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    alpha_scores = {}\n",
    "    \n",
    "    for alpha in ccp_alphas:\n",
    "        dt = DecisionTreeClassifier(random_state=1, ccp_alpha=alpha)\n",
    "        scores = cross_val_score(dt, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        alpha_scores[alpha] = np.mean(scores)\n",
    "    \n",
    "    best_alpha = max(alpha_scores, key=alpha_scores.get)\n",
    "    print(f\"Best ccp_alpha: {best_alpha:.6f} with Accuracy: {alpha_scores[best_alpha]:.4f}\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78fa67-0670-4eb6-ad2a-d08bd555028a",
   "metadata": {},
   "source": [
    " ### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2640862-1f0f-4c5b-a43e-cfdcb015cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find optimal ccp_alpha\n",
    "def find_optimal_alpha_full(Train):\n",
    "        # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets\n",
    "    train_results = []\n",
    "    for team, group in Train.groupby(\"Team\"):\n",
    "        result = rolling_averages(group, cols, new_cols)\n",
    "        train_results.append(result)\n",
    "    Train = pd.concat(train_results)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\",\"Rank\",\"IsRanked\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "\n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    path = dt.cost_complexity_pruning_path(Train[all_predictors], Train[\"Target\"])\n",
    "    ccp_alphas = path.ccp_alphas[:-1]  # Exclude the last value to avoid a single-node tree\n",
    " \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    alpha_scores = {}\n",
    "    \n",
    "    for alpha in ccp_alphas:\n",
    "        dt = DecisionTreeClassifier(random_state=1, ccp_alpha=alpha)\n",
    "        scores = cross_val_score(dt, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        alpha_scores[alpha] = np.mean(scores)\n",
    "    \n",
    "    best_alpha = max(alpha_scores, key=alpha_scores.get)\n",
    "    print(f\"Best ccp_alpha: {best_alpha:.6f} with Accuracy: {alpha_scores[best_alpha]:.4f}\")\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591f15f-b367-49c8-9389-59833539e72d",
   "metadata": {},
   "source": [
    "## **2. C in Logistic Regression**  \n",
    "In **Logistic Regression**, `C` is the **inverse of the regularization strength** (also called the **inverse of lambda** in regularization).\n",
    "\n",
    "$$ \n",
    "C = \\frac{1}{\\lambda}\n",
    "$$\n",
    "where **Œª (lambda)** is the regularization parameter.\n",
    "\n",
    "### üîπ What Does `C` Do?\n",
    "- It **controls the trade-off** between model complexity and generalization.\n",
    "- **Higher values of `C`** ‚Üí Less regularization (**more complex model, risk of overfitting**).\n",
    "- **Lower values of `C`** ‚Üí More regularization (**simpler model, avoids overfitting**).\n",
    "\n",
    "### üîπ Impact of `C` Values\n",
    "\n",
    "| `C` Value  | Effect on Model |\n",
    "|------------|---------------|\n",
    "| **Very Small (`C ‚Üí 0.0001`)** | Strong regularization, may underfit |\n",
    "| **Moderate (`C = 1.0`)** | Balanced regularization |\n",
    "| **Very Large (`C ‚Üí 10000`)** | Almost no regularization, may overfit |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb958025-448d-4cef-9ffb-937d563adbf2",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881ccfdb-be3e-4c48-bb41-e9b0ba65d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal C for Logistic Regression\n",
    "def find_optimal_C_base(Train):\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "\n",
    "    # Define a range of C values to test (logarithmically spaced)\n",
    "    C_values = np.logspace(-2, 3, 20)   # Testing C from 0.0001 to 10000\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    C_scores = {}\n",
    "\n",
    "    for C in C_values:\n",
    "        lr = LogisticRegression(C=C, solver='liblinear', random_state=1)\n",
    "        scores = cross_val_score(lr, Train[static_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        C_scores[C] = np.mean(scores)\n",
    "\n",
    "    best_C = max(C_scores, key=C_scores.get)\n",
    "    print(f\"Best C: {best_C:.6f} with Accuracy: {C_scores[best_C]:.4f}\")\n",
    "    return best_C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbad8da-4de2-4781-b1b4-88fd48ffedcb",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f1619ad-2d4d-42cd-9abc-6322a33dbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal C for Logistic Regression\n",
    "def find_optimal_C_roll(Train):\n",
    "   # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets\n",
    "    train_results = []\n",
    "    for team, group in Train.groupby(\"Team\"):\n",
    "        result = rolling_averages(group, cols, new_cols)\n",
    "        train_results.append(result)\n",
    "    Train = pd.concat(train_results)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "\n",
    "    # Define a range of C values to test (logarithmically spaced)\n",
    "    C_values = np.logspace(-2, 3, 20)   # Testing C from 0.0001 to 10000\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    C_scores = {}\n",
    "\n",
    "    for C in C_values:\n",
    "        lr = LogisticRegression(C=C, solver='liblinear', random_state=1)\n",
    "        scores = cross_val_score(lr, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        C_scores[C] = np.mean(scores)\n",
    "\n",
    "    best_C = max(C_scores, key=C_scores.get)\n",
    "    print(f\"Best C: {best_C:.6f} with Accuracy: {C_scores[best_C]:.4f}\")\n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4fc91-641e-4cb3-941d-c309c70d688d",
   "metadata": {},
   "source": [
    " ### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcffa8f4-9702-43fa-a8f3-5b86a7ab4499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal C for Logistic Regression\n",
    "def find_optimal_C_full(Train):\n",
    "   # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets\n",
    "    train_results = []\n",
    "    for team, group in Train.groupby(\"Team\"):\n",
    "        result = rolling_averages(group, cols, new_cols)\n",
    "        train_results.append(result)\n",
    "    Train = pd.concat(train_results)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\",\"Rank\",\"IsRanked\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "\n",
    "    # Define a range of C values to test (logarithmically spaced)\n",
    "    C_values = np.logspace(-2, 3, 20)   # Testing C from 0.0001 to 10000\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    C_scores = {}\n",
    "\n",
    "    for C in C_values:\n",
    "        lr = LogisticRegression(C=C, solver='liblinear', random_state=1)\n",
    "        scores = cross_val_score(lr, Train[all_predictors], Train[\"Target\"], cv=kf, scoring='accuracy')\n",
    "        C_scores[C] = np.mean(scores)\n",
    "\n",
    "    best_C = max(C_scores, key=C_scores.get)\n",
    "    print(f\"Best C: {best_C:.6f} with Accuracy: {C_scores[best_C]:.4f}\")\n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0ee13-1a59-4655-b8f7-d06d503f8e0e",
   "metadata": {},
   "source": [
    "# LDA Shrinkage\n",
    "## What is Shrinkage in LDA?\n",
    "Shrinkage is a regularization technique used in **Linear Discriminant Analysis (LDA)** to improve the estimation of the covariance matrix. It blends the empirical covariance matrix with a more structured version, reducing overfitting and improving stability, especially when dealing with high-dimensional data.\n",
    "\n",
    "## When and Why is Shrinkage Needed?\n",
    "- When **the number of features is large** compared to the number of samples, the empirical covariance matrix can be poorly estimated.\n",
    "- Shrinkage **adds regularization** to avoid overfitting and makes the model more robust.\n",
    "- It is useful when **the covariance matrix is nearly singular or unstable**.\n",
    "- Works **only with `solver=\"lsqr\"` or `solver=\"eigen\"`**, as these solvers allow regularization.\n",
    "\n",
    "## How is Shrinkage Controlled?\n",
    "The shrinkage parameter (`shrinkage`) is a value between **0 and 1**:\n",
    "- `shrinkage=0`: No shrinkage (uses the empirical covariance matrix).\n",
    "- `shrinkage=1`: Full shrinkage (uses a diagonalized covariance matrix).\n",
    "- **Optimal values** can be found via cross-validation (`GridSearchCV`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a011b-3a27-491e-86e1-d983580d902b",
   "metadata": {},
   "source": [
    "### Baseline Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "436fb53e-09bc-4ec5-a13b-b488ba0814ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_shrinkage_base(Train):\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    param_grid ={\"shrinkage\": np.linspace(0.0, 1.0, 10)}\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"lsqr\")\n",
    "    grid_search = GridSearchCV(lda, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "    return grid_search.best_params_[\"shrinkage\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05853a2a-d0b3-4000-95f1-0d0c87078896",
   "metadata": {},
   "source": [
    "### Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98705229-462d-441a-8cda-2e220b4c3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_shrinkage_roll(Train):\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets\n",
    "    train_results = []\n",
    "    for team, group in Train.groupby(\"Team\"):\n",
    "        result = rolling_averages(group, cols, new_cols)\n",
    "        train_results.append(result)\n",
    "    Train = pd.concat(train_results)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "\n",
    "    param_grid = {\"shrinkage\": np.linspace(0.0, 1.0, 10)}\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"lsqr\")\n",
    "    grid_search = GridSearchCV(lda, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "    return grid_search.best_params_[\"shrinkage\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8573c-073c-4787-ab6d-4e4532236eef",
   "metadata": {},
   "source": [
    " ### Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d398db6-4a38-4885-9b32-ac0218cf89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_shrinkage_full(Train):\n",
    "     # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets\n",
    "    train_results = []\n",
    "    for team, group in Train.groupby(\"Team\"):\n",
    "        result = rolling_averages(group, cols, new_cols)\n",
    "        train_results.append(result)\n",
    "    Train = pd.concat(train_results)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\",\"Rank\",\"IsRanked\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "\n",
    "    param_grid = {\"shrinkage\": np.linspace(0.0, 1.0, 10)}\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"lsqr\")\n",
    "    grid_search = GridSearchCV(lda, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[all_predictors], Train[\"Target\"])\n",
    "    return grid_search.best_params_[\"shrinkage\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc3c7f-2d89-4cf6-a995-63318a30f781",
   "metadata": {},
   "source": [
    "# **QDA Regularization Parameter (`reg_param`)**\n",
    "\n",
    "## What is `reg_param` in QDA?\n",
    "`reg_param` is a regularization parameter in **Quadratic Discriminant Analysis (QDA)** that **adds shrinkage** to the covariance matrix. It prevents overfitting by **regularizing class-specific covariance matrices**, making the model more stable in cases with small sample sizes or highly correlated features.\n",
    "\n",
    "## When and Why is `reg_param` Needed?\n",
    "- **High-dimensional data**: If the number of features is large compared to available samples, `reg_param` helps by **shrinking covariance estimates**.\n",
    "- **Ill-conditioned covariance matrix**: When the covariance matrix is near-singular, `reg_param` helps stabilize it.\n",
    "- **Prevents overfitting**: Adding shrinkage smooths class-specific covariance estimates, making QDA more generalizable.\n",
    "\n",
    "## How is `reg_param` Controlled?\n",
    "The value of `reg_param` typically ranges from **0 to 1**:\n",
    "- `reg_param=0`: No regularization (pure QDA).\n",
    "- `reg_param=1`: Maximum shrinkage (covariance matrix becomes diagonal).\n",
    "- **Tuned using cross-validation** (`GridSearchCV`) for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6aba93-b272-4d07-9a58-caf0fa908eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_shrinkage_base(Train):\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "# Generate a range of values between 0 and 1 with 10 steps\n",
    "    param_grid = {\"reg_param\": np.linspace(0.0, 1.0, 10)}\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    grid_search = GridSearchCV(qda, param_grid, scoring=\"accuracy\", cv=5)\n",
    "    grid_search.fit(Train[static_predictors], Train[\"Target\"])\n",
    "\n",
    "    return grid_search.best_params_[\"reg_param\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
