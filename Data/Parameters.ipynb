{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15cd30e6-cc15-4d78-83ac-123ca96a2f7b",
   "metadata": {},
   "source": [
    "# Parameters For Cross Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d99bf-5439-4cd8-a46f-b8f2d28dc9bf",
   "metadata": {},
   "source": [
    "## Baseline Predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c72f88f4-f0d3-48b7-8863-1b8b513b734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parameters_base(Train) : \n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    return static_predictors                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e3983-dafa-477a-9b59-a738f7e7c43f",
   "metadata": {},
   "source": [
    "##  Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0cbfbd2-654d-4d10-b915-bc2b099cf8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(A) :\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    train_results = []\n",
    "    for team, group in A.groupby(\"Team\"):\n",
    "        result = rolling_averages(group, cols, new_cols)\n",
    "        train_results.append(result)\n",
    "    Train = pd.concat(train_results)\n",
    "    return Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1beb6cc7-1f24-41fc-8cf7-513aaa6a804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parameters_roll(Train) :\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets\n",
    "    Train = roll(Train)\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "    return all_predictors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc430d0-56c6-4d5e-b879-204dbd3bef4b",
   "metadata": {},
   "source": [
    "## Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "939fdb84-cd93-4ebb-88f6-b9bc4639aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_parameters_full(Train) :\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\",]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets\n",
    "    Train = roll(Train)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\",\"Rank\",\"IsRanked\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "    return all_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f30e3-c235-440c-b28e-7922b78ee176",
   "metadata": {},
   "source": [
    "# Parameters For Models Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f345e9-844c-4955-a6ac-9da80da925f1",
   "metadata": {},
   "source": [
    "## Baseline Predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a80dc7f0-b7f6-4e7d-8f56-da266af49eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_base(Train,Test) : \n",
    "\n",
    "     # Convert 'Date' columns to datetime and sort data\n",
    "    Train['Date'] = pd.to_datetime(Train['Date'], errors='coerce')\n",
    "    Test['Date'] = pd.to_datetime(Test['Date'], errors='coerce')\n",
    "    Train = Train.dropna(subset=['Date']).sort_values(by='Date')\n",
    "    Test = Test.dropna(subset=['Date']).sort_values(by='Date')\n",
    "\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    return static_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181aa842-eece-4c07-8061-689d14fd637d",
   "metadata": {},
   "source": [
    "##  Baseline Predictors + Rolling Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca0d2ab0-f7d0-4dd3-9264-f148f52da8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_roll(Train,Test) :\n",
    "\n",
    "     # Convert 'Date' columns to datetime and sort data\n",
    "    Train['Date'] = pd.to_datetime(Train['Date'], errors='coerce')\n",
    "    Test['Date'] = pd.to_datetime(Test['Date'], errors='coerce')\n",
    "    Train = Train.dropna(subset=['Date']).sort_values(by='Date')\n",
    "    Test = Test.dropna(subset=['Date']).sort_values(by='Date')\n",
    "\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets  \n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "    return all_predictors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799a453-40f3-4163-ae3a-003432e6580f",
   "metadata": {},
   "source": [
    "## Full Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4956bc9d-142f-4fb7-9200-2bfb8d8be35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_full(Train,Test) :\n",
    "\n",
    "     # Convert 'Date' columns to datetime and sort data\n",
    "    Train['Date'] = pd.to_datetime(Train['Date'], errors='coerce')\n",
    "    Test['Date'] = pd.to_datetime(Test['Date'], errors='coerce')\n",
    "    Train = Train.dropna(subset=['Date']).sort_values(by='Date')\n",
    "    Test = Test.dropna(subset=['Date']).sort_values(by='Date')\n",
    "\n",
    "    # Define the feature columns for which we'll calculate rolling averages\n",
    "    cols = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "    new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "    \n",
    "    # Apply rolling averages to both Train and Test datasets  \n",
    "    Train = roll(Train)\n",
    "    Test  = roll(Test)\n",
    "\n",
    "    # Define static and rolling predictors\n",
    "    static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\",\"Rank\",\"IsRanked\"]\n",
    "    rolling_predictors = new_cols\n",
    "    all_predictors = static_predictors + rolling_predictors\n",
    "    return all_predictors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
