{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02986de0-943a-4fd7-854d-5a7592f086d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df45c223-33d1-42f6-a0e4-78827eeca076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vedsh\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55517a54-0690-44b1-adbd-924770af5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(\"premierleague_team_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3766b7c7-337f-4308-8934-c8a51e8ed47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches = pd.read_csv(\"premierleague_test_team_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42db90c-15e7-492e-83ee-0bcca87ac4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team\n",
       "ManchesterCity           190\n",
       "ManchesterUnited         190\n",
       "TottenhamHotspur         190\n",
       "Liverpool                190\n",
       "Chelsea                  190\n",
       "Arsenal                  190\n",
       "Everton                  190\n",
       "CrystalPalace            190\n",
       "Southampton              190\n",
       "SwanseaCity              190\n",
       "StokeCity                190\n",
       "WestHamUnited            190\n",
       "WestBromwichAlbion       190\n",
       "Sunderland               152\n",
       "LeicesterCity            152\n",
       "NewcastleUnited          152\n",
       "Bournemouth              114\n",
       "Burnley                  114\n",
       "HullCity                 114\n",
       "Watford                  114\n",
       "AstonVilla               114\n",
       "NorwichCity               76\n",
       "BrightonandHoveAlbion     38\n",
       "HuddersfieldTown          38\n",
       "Middlesbrough             38\n",
       "QueensParkRangers         38\n",
       "Fulham                    38\n",
       "CardiffCity               38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[\"Team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0f797d-c447-4edf-97e6-67e50aca444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"Date\"] = pd.to_datetime(matches[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82819756-d0b9-4447-9d32-9ab79acadfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches[\"Date\"] = pd.to_datetime(test_matches[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ce6aa5-133b-46d8-b0ab-138e6ddca004",
   "metadata": {},
   "outputs": [],
   "source": [
    " matches[\"Venue_code\"] = matches[\"Venue\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea429ea-7580-4853-b55e-32e1eb6b3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches[\"Venue_code\"] = test_matches[\"Venue\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d72a41-857b-461c-9521-779aa49a979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"Opp_code\"] = matches[\"Opponent\"].astype(\"category\").cat.codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be689b01-bbaa-4263-8e00-83c28453146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches[\"Opp_code\"] = test_matches[\"Opponent\"].astype(\"category\").cat.codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e94975-41f1-449b-b4d8-eb03eba778b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"Hour\"] = matches[\"Time\"].str.replace(\":.+\", \"\", regex=True).fillna(\"0\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c3bdee-4e93-4810-9045-cfafb19cc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches[\"Hour\"] = test_matches[\"Time\"].str.replace(\":.+\", \"\", regex=True).fillna(\"0\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04cdc632-cabc-4500-bef6-6520bccce612",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"Day_code\"] = matches[\"Date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68ee8910-31d6-4bb3-b9b9-2c9e2ebf30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches[\"Day_code\"] = test_matches[\"Date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbafb09-f35a-4614-ba2e-60f870c602b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"Target\"]=(matches[\"Result\"] == \"W\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada9a2a1-2688-4c10-92e9-8f17fd1395c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches[\"Target\"]=(test_matches[\"Result\"] == \"W\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf89a69e-90d3-47b6-9ada-2a302bfa30ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: Accuracy = 0.5882, Precision = 0.5740\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data\n",
    "train = matches\n",
    "test = test_matches\n",
    "\n",
    "# Sort data by date\n",
    "train = train.sort_values(by='Date')\n",
    "test = test.sort_values(by='Date')\n",
    "\n",
    "# Model training\n",
    "predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)\n",
    "rf.fit(train[predictors], train[\"Target\"])\n",
    "\n",
    "# Make predictions\n",
    "preds = rf.predict(test[predictors])\n",
    "    \n",
    "# Test the model on each yearly split\n",
    "results = []\n",
    "\n",
    " # Calculate metrics\n",
    "accuracy = accuracy_score(test[\"Target\"], preds)\n",
    "precision = precision_score(test[\"Target\"], preds, average=\"weighted\")\n",
    "print(f\"Metrics: Accuracy = {accuracy:.4f}, Precision = {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "756de0cc-8611-4ce3-99f7-e41b3d3feaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available years for testing data: [2019, 2020, 2021, 2022, 2023]\n",
      "Year 2019: Accuracy = 0.6055, Precision = 0.5884\n",
      "Year 2020: Accuracy = 0.6027, Precision = 0.5917\n",
      "Year 2021: Accuracy = 0.5760, Precision = 0.5594\n",
      "Year 2022: Accuracy = 0.5956, Precision = 0.5830\n",
      "Year 2023: Accuracy = 0.5602, Precision = 0.5462\n",
      "\n",
      "Overall Results:\n",
      "   Year  Accuracy  Precision\n",
      "0  2019  0.605528   0.588351\n",
      "1  2020  0.602679   0.591718\n",
      "2  2021  0.575980   0.559401\n",
      "3  2022  0.595568   0.582976\n",
      "4  2023  0.560185   0.546172\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Load training and testing data\n",
    "train = matches\n",
    "test = test_matches\n",
    "\n",
    "\n",
    "# Sort data by date\n",
    "train = train.sort_values(by='Date')\n",
    "test = test.sort_values(by='Date')\n",
    "\n",
    "# Create yearly splits for testing\n",
    "test_splits = {}\n",
    "for year in range(test['Date'].dt.year.min(), test['Date'].dt.year.max() + 1):\n",
    "    yearly_data = test[test['Date'].dt.year == year]\n",
    "    if not yearly_data.empty:\n",
    "        test_splits[year] = yearly_data\n",
    "\n",
    "# Output available years\n",
    "print(\"Available years for testing data:\", list(test_splits.keys()))\n",
    "\n",
    "# Model training\n",
    "predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)\n",
    "\n",
    "rf.fit(train[predictors], train[\"Target\"])\n",
    "\n",
    "# Test the model on each yearly split\n",
    "results = []\n",
    "for year, test_data in test_splits.items():\n",
    "    # Make predictions\n",
    "    preds = rf.predict(test_data[predictors])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_data[\"Target\"], preds)\n",
    "    precision = precision_score(test_data[\"Target\"], preds, average=\"weighted\")\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\"Year\": year, \"Accuracy\": accuracy, \"Precision\": precision})\n",
    "\n",
    "    print(f\"Year {year}: Accuracy = {accuracy:.4f}, Precision = {precision:.4f}\")\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50d8ccdb-9106-4bbd-b0ca-b8bb8d5cda33",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_matches = matches.groupby(\"Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e8340e1-4d0b-4f9a-9a6e-769c9c5f85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_test_matches = test_matches.groupby(\"Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aba85672-be9f-46d3-9a4c-7a47ef339c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_averages(group, cols, new_cols):\n",
    "    # Sort the group by the \"Date\" column to ensure chronological order\n",
    "    group = group.sort_values(\"Date\")\n",
    "    \n",
    "    # Calculate rolling averages over a window of 3 rows, excluding the current row\n",
    "    # (e.g., for row N, it computes the average of rows N-1, N-2, and N-3)\n",
    "    rolling_stats = group[cols].rolling(3, closed='left').mean()\n",
    "    \n",
    "    # Assign the calculated rolling averages to new columns in the group\n",
    "    group[new_cols] = rolling_stats\n",
    "    \n",
    "    # Drop rows where the new rolling average columns contain NaN values\n",
    "    # (occurs when there aren't enough previous rows to calculate the average)\n",
    "    group = group.dropna(subset=new_cols)\n",
    "    \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54691979-4861-4d98-af35-ce120703f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ \"GF\",\"GA\",\"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2580b17c-b1fa-40f1-8400-e877bec6e846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GF_rolling',\n",
       " 'GA_rolling',\n",
       " 'Sh_rolling',\n",
       " 'SoT_rolling',\n",
       " 'PK_rolling',\n",
       " 'PKatt_rolling']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f5efbd8-fb13-4d5d-8cc0-a89318de623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for team, group in matches.groupby(\"Team\"):\n",
    "    # Apply rolling averages to each group\n",
    "    result = rolling_averages(group, cols, new_cols)\n",
    "    results.append(result)\n",
    "\n",
    "# Concatenate all results into one DataFrame\n",
    "matches_rolling = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9339129-7fa0-43aa-8fe5-74013015aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for team, group in test_matches.groupby(\"Team\"):\n",
    "    # Apply rolling averages to each group\n",
    "    result = rolling_averages(group, cols, new_cols)\n",
    "    results.append(result)\n",
    "\n",
    "# Concatenate all results into one DataFrame\n",
    "test_matches_rolling = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "946b269a-5216-48cc-ba71-8a75f3901acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_rolling.index = range(matches_rolling.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f99f5a1d-d256-4451-bb4c-1bead11b7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matches_rolling.index = range(test_matches_rolling.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf1be66c-8f92-4abd-8914-451b6051fafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on year: 2019 with 398 matches.\n",
      "Year 2019: Precision = 0.6827, Accuracy = 0.6910\n",
      "\n",
      "Testing on year: 2020 with 672 matches.\n",
      "Year 2020: Precision = 0.6863, Accuracy = 0.6949\n",
      "\n",
      "Testing on year: 2021 with 816 matches.\n",
      "Year 2021: Precision = 0.7106, Accuracy = 0.7145\n",
      "\n",
      "Testing on year: 2022 with 722 matches.\n",
      "Year 2022: Precision = 0.7025, Accuracy = 0.7078\n",
      "\n",
      "Testing on year: 2023 with 432 matches.\n",
      "Year 2023: Precision = 0.7045, Accuracy = 0.7106\n",
      "\n",
      "Yearly Predictions and Metrics:\n",
      "      Precision  Accuracy\n",
      "Year                     \n",
      "2019   0.682671  0.690955\n",
      "2020   0.686260  0.694940\n",
      "2021   0.710623  0.714461\n",
      "2022   0.702541  0.707756\n",
      "2023   0.704528  0.710648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_rolling_features(df, columns, window_size):\n",
    "    for col in columns:\n",
    "        df[f\"{col}_rolling\"] = df[col].rolling(window=window_size, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def make_yearly_predictions_with_rolling(train, test, predictors, rolling_predictors):\n",
    "    train['Date'] = pd.to_datetime(train['Date'], errors='coerce')\n",
    "    test['Date'] = pd.to_datetime(test['Date'], errors='coerce')\n",
    "    train = train.dropna(subset=['Date']).sort_values(by='Date')\n",
    "    test = test.dropna(subset=['Date']).sort_values(by='Date')\n",
    "\n",
    "    all_predictors = predictors + rolling_predictors\n",
    "\n",
    "    yearly_results = []\n",
    "    for year in range(test['Date'].dt.year.min(), test['Date'].dt.year.max() + 1):\n",
    "        test_year = test[test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            print(f\"\\nTesting on year: {year} with {len(test_year)} matches.\")\n",
    "            rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)\n",
    "            rf.fit(train[all_predictors], train[\"Target\"])\n",
    "            preds = rf.predict(test_year[all_predictors])\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\")\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "            combined = pd.DataFrame({\n",
    "                \"Year\": year,\n",
    "                \"Actual\": test_year[\"Target\"],\n",
    "                \"Prediction\": preds,\n",
    "                \"Precision\": [precision] * len(test_year),\n",
    "                \"Accuracy\": [accuracy] * len(test_year)\n",
    "            })\n",
    "            yearly_results.append(combined)\n",
    "            print(f\"Year {year}: Precision = {precision:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    results = pd.concat(yearly_results, ignore_index=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "train = matches\n",
    "test = test_matches\n",
    "\n",
    "# Define predictors\n",
    "static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "rolling_predictors = [\"GF_rolling\", \"GA_rolling\", \"Sh_rolling\", \"SoT_rolling\", \"PK_rolling\", \"PKatt_rolling\"]\n",
    "\n",
    "# Generate rolling features\n",
    "feature_columns = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "train = calculate_rolling_features(train, feature_columns, window_size=5)\n",
    "test = calculate_rolling_features(test, feature_columns, window_size=5)\n",
    "\n",
    "# Run the prediction function\n",
    "results = make_yearly_predictions_with_rolling(train, test, static_predictors, rolling_predictors)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nYearly Predictions and Metrics:\")\n",
    "print(results.groupby(\"Year\")[[\"Precision\", \"Accuracy\"]].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c65b8de-4fc8-483e-a991-6420ad1cde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches = pd.read_csv(\"premierleague_rank_team_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42e06458-f433-4c03-84e8-b70a0a616d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_matches = pd.read_csv(\"premierleague_rank_test_team_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1752eaf-afa4-46c7-9b7a-1416b9d2a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches[\"Date\"] = pd.to_datetime(new_matches[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62f33c97-2113-4842-b38c-b06117ccefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_matches[\"Date\"] = pd.to_datetime(new_test_matches[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71a86e64-5a0d-4e37-8f23-a1ca58bef2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches[\"Venue_code\"] = new_matches[\"Venue\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e30f5d4-d028-40a5-aa4b-c7e18826ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_matches[\"Venue_code\"] = new_test_matches[\"Venue\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9549fbaa-cd1c-4b2f-af9f-804d9a3d69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches[\"Opp_code\"] = new_matches[\"Opponent\"].astype(\"category\").cat.codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2466bec-e1f5-400e-8143-5275d6fed67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_matches[\"Opp_code\"] = new_test_matches[\"Opponent\"].astype(\"category\").cat.codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0650fec3-e213-4804-96fa-adad3c1cdec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches[\"Hour\"] = new_matches[\"Time\"].str.replace(\":.+\", \"\", regex=True).fillna(\"0\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76eda873-520c-42db-82af-4c42ea3d4582",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_matches[\"Hour\"] = new_test_matches[\"Time\"].str.replace(\":.+\", \"\", regex=True).fillna(\"0\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b1bae59-6a55-4ca6-b1ba-41723a3a41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches[\"Day_code\"] = new_matches[\"Date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bbf795d-9580-4519-a931-07d59dd6eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_matches[\"Day_code\"] = new_test_matches[\"Date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45add895-8abe-4624-92c6-d5d25e4cbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches[\"Target\"]=(new_matches[\"Result\"] == \"W\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52f8f342-a674-40a9-b1f3-081dbb4ca6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_matches[\"Target\"]=(new_test_matches[\"Result\"] == \"W\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2af93803-e1f0-40b7-bcb8-fb7c98e8ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: Accuracy = 0.6237, Precision = 0.6071\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data\n",
    "train = new_matches\n",
    "test = new_test_matches\n",
    "\n",
    "# Sort data by date\n",
    "train = train.sort_values(by='Date')\n",
    "test = test.sort_values(by='Date')\n",
    "\n",
    "# Model training\n",
    "predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\",\"Rank\",\"IsRanked\"]\n",
    "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)\n",
    "rf.fit(train[predictors], train[\"Target\"])\n",
    "\n",
    "# Make predictions\n",
    "preds = rf.predict(test[predictors])\n",
    "    \n",
    "# Test the model on each yearly split\n",
    "results = []\n",
    "\n",
    " # Calculate metrics\n",
    "accuracy = accuracy_score(test[\"Target\"], preds)\n",
    "precision = precision_score(test[\"Target\"], preds, average=\"weighted\")\n",
    "print(f\"Metrics: Accuracy = {accuracy:.4f}, Precision = {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07444361-35bd-428a-a0ca-8342cc90854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available years for testing data: [2019, 2020, 2021, 2022, 2023]\n",
      "Year 2019: Accuracy = 0.6206, Precision = 0.5967\n",
      "Year 2020: Accuracy = 0.6369, Precision = 0.6247\n",
      "Year 2021: Accuracy = 0.6213, Precision = 0.6053\n",
      "Year 2022: Accuracy = 0.6205, Precision = 0.6055\n",
      "Year 2023: Accuracy = 0.6157, Precision = 0.5956\n",
      "\n",
      "Overall Results:\n",
      "   Year  Accuracy  Precision\n",
      "0  2019  0.620603   0.596717\n",
      "1  2020  0.636905   0.624673\n",
      "2  2021  0.621324   0.605319\n",
      "3  2022  0.620499   0.605483\n",
      "4  2023  0.615741   0.595612\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Load training and testing data\n",
    "train = new_matches\n",
    "test = new_test_matches\n",
    "\n",
    "\n",
    "# Sort data by date\n",
    "train = train.sort_values(by='Date')\n",
    "test = test.sort_values(by='Date')\n",
    "\n",
    "# Create yearly splits for testing\n",
    "test_splits = {}\n",
    "for year in range(test['Date'].dt.year.min(), test['Date'].dt.year.max() + 1):\n",
    "    yearly_data = test[test['Date'].dt.year == year]\n",
    "    if not yearly_data.empty:\n",
    "        test_splits[year] = yearly_data\n",
    "\n",
    "# Output available years\n",
    "print(\"Available years for testing data:\", list(test_splits.keys()))\n",
    "\n",
    "# Model training\n",
    "predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\",\"Rank\",\"IsRanked\"]\n",
    "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)\n",
    "\n",
    "rf.fit(train[predictors], train[\"Target\"])\n",
    "\n",
    "# Test the model on each yearly split\n",
    "results = []\n",
    "for year, test_data in test_splits.items():\n",
    "    # Make predictions\n",
    "    preds = rf.predict(test_data[predictors])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(test_data[\"Target\"], preds)\n",
    "    precision = precision_score(test_data[\"Target\"], preds, average=\"weighted\")\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\"Year\": year, \"Accuracy\": accuracy, \"Precision\": precision})\n",
    "\n",
    "    print(f\"Year {year}: Accuracy = {accuracy:.4f}, Precision = {precision:.4f}\")\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nOverall Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "504c9b44-3c5e-44a2-a6a4-7639fa1b18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = []\n",
    "for team, group in new_matches.groupby(\"Team\"):\n",
    "    # Apply rolling averages to each group\n",
    "    new_result = rolling_averages(group, cols, new_cols)\n",
    "    new_results.append(new_result)\n",
    "\n",
    "# Concatenate all results into one DataFrame\n",
    "new_matches_rolling = pd.concat(new_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "598b88e9-e620-4c78-bebf-0781607ca2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_results = []\n",
    "for team, group in new_test_matches.groupby(\"Team\"):\n",
    "    # Apply rolling averages to each group\n",
    "    new_result = rolling_averages(group, cols, new_cols)\n",
    "    new_results.append(new_result)\n",
    "\n",
    "# Concatenate all results into one DataFrame\n",
    "new_test_matches_rolling = pd.concat(new_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "810b48fe-bbe8-4af8-ab34-c95619d8dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_matches_rolling.index = range(new_matches_rolling.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "362758b8-4ea0-4438-a75d-94378275344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on year: 2019 with 398 matches.\n",
      "Year 2019: Precision = 0.7152, Accuracy = 0.7211\n",
      "\n",
      "Testing on year: 2020 with 672 matches.\n",
      "Year 2020: Precision = 0.7170, Accuracy = 0.7232\n",
      "\n",
      "Testing on year: 2021 with 816 matches.\n",
      "Year 2021: Precision = 0.7021, Accuracy = 0.7083\n",
      "\n",
      "Testing on year: 2022 with 722 matches.\n",
      "Year 2022: Precision = 0.7172, Accuracy = 0.7216\n",
      "\n",
      "Testing on year: 2023 with 432 matches.\n",
      "Year 2023: Precision = 0.6558, Accuracy = 0.6667\n",
      "\n",
      "Yearly Predictions and Metrics:\n",
      "      Precision  Accuracy\n",
      "Year                     \n",
      "2019   0.715211  0.721106\n",
      "2020   0.716971  0.723214\n",
      "2021   0.702081  0.708333\n",
      "2022   0.717218  0.721607\n",
      "2023   0.655808  0.666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_rolling_features(df, columns, window_size):\n",
    "    for col in columns:\n",
    "        df[f\"{col}_rolling\"] = df[col].rolling(window=window_size, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def make_yearly_predictions_with_rolling(train, test, predictors, rolling_predictors):\n",
    "    train['Date'] = pd.to_datetime(train['Date'], errors='coerce')\n",
    "    test['Date'] = pd.to_datetime(test['Date'], errors='coerce')\n",
    "    train = train.dropna(subset=['Date']).sort_values(by='Date')\n",
    "    test = test.dropna(subset=['Date']).sort_values(by='Date')\n",
    "\n",
    "    all_predictors = predictors + rolling_predictors\n",
    "\n",
    "    yearly_results = []\n",
    "    for year in range(test['Date'].dt.year.min(), test['Date'].dt.year.max() + 1):\n",
    "        test_year = test[test['Date'].dt.year == year]\n",
    "        if not test_year.empty:\n",
    "            print(f\"\\nTesting on year: {year} with {len(test_year)} matches.\")\n",
    "            rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, random_state=1)\n",
    "            rf.fit(train[all_predictors], train[\"Target\"])\n",
    "            preds = rf.predict(test_year[all_predictors])\n",
    "            precision = precision_score(test_year[\"Target\"], preds, average=\"weighted\")\n",
    "            accuracy = accuracy_score(test_year[\"Target\"], preds)\n",
    "            combined = pd.DataFrame({\n",
    "                \"Year\": year,\n",
    "                \"Actual\": test_year[\"Target\"],\n",
    "                \"Prediction\": preds,\n",
    "                \"Precision\": [precision] * len(test_year),\n",
    "                \"Accuracy\": [accuracy] * len(test_year)\n",
    "            })\n",
    "            yearly_results.append(combined)\n",
    "            print(f\"Year {year}: Precision = {precision:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    results = pd.concat(yearly_results, ignore_index=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "train = new_matches\n",
    "test = new_test_matches\n",
    "\n",
    "# Define predictors\n",
    "static_predictors = [\"Venue_code\", \"Opp_code\", \"Hour\", \"Day_code\"]\n",
    "rolling_predictors = [\"GF_rolling\", \"GA_rolling\", \"Sh_rolling\", \"SoT_rolling\", \"PK_rolling\", \"PKatt_rolling\",\"Rank\", \"IsRanked\"]\n",
    "\n",
    "# Generate rolling features\n",
    "feature_columns = [\"GF\", \"GA\", \"Sh\", \"SoT\", \"PK\", \"PKatt\"]\n",
    "train = calculate_rolling_features(train, feature_columns, window_size=5)\n",
    "test = calculate_rolling_features(test, feature_columns, window_size=5)\n",
    "\n",
    "# Run the prediction function\n",
    "results = make_yearly_predictions_with_rolling(train, test, static_predictors, rolling_predictors)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nYearly Predictions and Metrics:\")\n",
    "print(results.groupby(\"Year\")[[\"Precision\", \"Accuracy\"]].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1e350-7a4a-4cd2-9a9a-febf40dd4996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
